<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="Natural Language Processing"><title>COMP90042</title>
<link rel=canonical href=https://shyu216.github.io/aquamega/p/comp90042/><link rel=stylesheet href=/aquamega/scss/style.min.0304c6baf04e01a8fe70693791cb744d56a3578a3120a8796cefc66825aa39c7.css><meta property='og:title' content="COMP90042"><meta property='og:description' content="Natural Language Processing"><meta property='og:url' content='https://shyu216.github.io/aquamega/p/comp90042/'><meta property='og:site_name' content='Dale的水硕日记'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='24s1'><meta property='article:tag' content='AI'><meta property='article:published_time' content='2024-06-09T00:00:00+00:00'><meta property='article:modified_time' content='2024-06-09T00:00:00+00:00'><meta name=twitter:title content="COMP90042"><meta name=twitter:description content="Natural Language Processing"><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/aquamega/><img src=https://github.com/shyu216.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🦟</span></figure><div class=site-meta><h1 class=site-name><a href=/aquamega>Dale的水硕日记</a></h1><h2 class=site-description>不定期更新</h2></div></header><ol class=menu-social><li><a href=https://github.com/shyu216 target=_blank title=GitHub rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://www.linkedin.com/in/sihong-yu-a35b30205/ target=_blank title=Linkedin rel=me><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-brand-linkedin"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 4m0 2a2 2 0 012-2h12a2 2 0 012 2v12a2 2 0 01-2 2H6a2 2 0 01-2-2z"/><path d="M8 11v5"/><path d="M8 8v.01"/><path d="M12 16v-5"/><path d="M16 16v-3a2 2 0 00-4 0"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/aquamega/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/aquamega/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/aquamega/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#vocab>Vocab</a></li><li><a href=#information-bottleneck>Information Bottleneck</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/aquamega/categories/comp90042/ style=background-color:#54ab11;color:#fff>COMP90042</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/aquamega/p/comp90042/>COMP90042</a></h2><h3 class=article-subtitle>Natural Language Processing</h3></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Jun 09, 2024</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>3 minute read</time></div></footer></div></header><section class=article-content><ol><li>Preprocessing<ol><li>Sentence segmentation</li><li>Tokenization, subword tokenization</li><li>Word normalization<ol><li>Inflectional vs derivational morphology</li><li>Lemmatization vs stemming</li></ol></li><li>Stopword removal</li></ol></li><li>N-gram Language Model<ol><li>Derivation</li><li>Smoothing techniques<ol><li>Add-k</li><li>Absolute discounting</li><li>Katz backoff</li><li>Kneser-Ney smoothing</li><li>Interpolation</li></ol></li></ol></li><li>Text Classification<ol><li>Build a classifier</li><li>Task<ol><li>Topic classification</li><li>Sentiment analysis</li><li>Native language identification</li></ol></li><li>Algorithms<ol><li>Naive Bayes, logistic regression, SVM</li><li>kNN, neural networks</li></ol></li><li>Bias vs variance：欠拟合under和过拟合over的取舍</li><li>Evaluation<ol><li>Precision, recall, F1</li></ol></li></ol></li><li>Part of Speech Tagging<ol><li>English POS<ol><li>Closed vs open classes</li></ol></li><li>Tagsets<ol><li>Penn Treebank tagset</li></ol></li><li>Automatic taggers<ol><li>Rule-based</li><li>Statistical<ol><li>Unigram, classifier-based, HMM</li></ol></li></ol></li></ol></li><li>Hidden Markov Model<ol><li>Probabilistic formulation:<ol><li>Emission & Transition</li></ol></li><li>Training</li><li>Viterbi algorithm</li><li>Generative vs discriminative models</li></ol></li><li>Feedforward Neural Network<ol><li>Formulation</li><li>Tasks:<ol><li>Topic classifcation</li><li>Language models</li><li>POS tagging</li></ol></li><li>Word embeddings</li><li>Convolutional networks</li></ol></li><li>Recurrent Neural Network<ol><li>Formulation</li><li>RNN: language models</li><li>LSTM:<ol><li>Functions of gates</li><li>Variants</li></ol></li><li>Tasks:<ol><li>Text classification: sentiment analysis</li><li>POS tagging</li></ol></li></ol></li><li>Lexical Semantics<ol><li>Definition of word sense, gloss</li><li>Lexical Relationship:<ol><li>Synonymy, antonymy, hypernymy, meronymy</li></ol></li><li>Structure of wordnet</li><li>Word similarity<ol><li>Path lenght</li><li>Depth information</li><li>Information content</li></ol></li><li>Word sense unambiguation<ol><li>supervised, unsupervised</li></ol></li></ol></li><li>Distributional Semantics<ol><li>Matrices:<ol><li>VSM, TF-IDF, word-word co-occurrence</li></ol></li><li>Association measures: PMI, PPMI</li><li>Count-based method: SVM</li><li>Neural method: skip-gram, CBOW</li><li>Evaluation:<ol><li>Word similarity, analogy</li></ol></li></ol></li><li>Contextual Representation<ol><li>Formulation with RNN</li><li>ELMo</li><li>BERT<ol><li>Objective</li><li>Fine-tuning for downstream tasks</li></ol></li><li>Transformers<ol><li>Multi-head attention</li></ol></li></ol></li></ol><p>Second half:</p><ol><li>Attention<ol><li>Sequential model with attention</li><li>Attention variants:<ol><li>Concat</li><li>Dot product</li><li>Scaled dot product</li><li>Location-based</li><li>Cosine similarity</li></ol></li><li>Global vs local attention</li><li>Self-attention</li></ol></li><li>Machine Translation<ol><li>Statistical MT</li><li>Neural MT with teacher forcing</li></ol></li><li>Transformer<ol><li>Mutli-head self-attention</li><li>Position encoding</li></ol></li><li>Pretrained Language Models<ol><li>Encoder architecture<ol><li>BERT</li><li>bidirectional context</li><li>good for classification</li></ol></li><li>Encoder-decoder architecture</li><li>Decoder architecture<ol><li>GPT</li><li>unidirectional context</li><li>good for generation</li></ol></li></ol></li><li>Large Language Models<ol><li>In-context learning</li><li>Step-by-step reasoning</li><li>Human-feedback reinforcement</li><li>Instruction following</li></ol></li><li>Named Entity Recognition<ol><li>Predict entities in a text</li><li>Traditional ML methods</li><li>Bi-LSTM with another RNN/CRF</li><li>Multi-aspect NER</li></ol></li><li>Coreference Resolution 共指消解<ol><li>Coreference, anaphora</li><li>B-Cubed metric</li></ol></li><li>Question Answering and Reading Comprehension<ol><li>Knowledge-based QA</li><li>Visual QA</li></ol></li><li>Spoken Language Understanding<ol><li>Attention RNNs</li><li>Joint BERT</li><li>Tri-level model</li><li>Explainable NLU</li></ol></li><li>Vision Language Pretrained Model<ol><li>V-L Interaction Model<ol><li>Self-attention, co-attention, VSE</li></ol></li><li>Constrastive Language-Image Pretraining</li></ol></li><li>Ethics<ol><li>Sotial bias 刻板印象</li><li>Incivility 仇恨言论</li><li>Privacy Violation 歧视</li><li>Misinformation 谣言</li><li>Technological divide 发展不平衡</li></ol></li></ol><h2 id=vocab>Vocab</h2><ul><li>stemming:词干提取，去掉后缀，通常不是个词</li><li>lemmatisation:词形还原</li><li>morphology <strong>詞法學</strong></li><li>lexicon 字典</li><li>corpus 语料</li><li>tokenization 分词</li><li>entailment vs. contradiction 蕴涵与矛盾</li><li>neutral 中性</li><li>vanish 消失</li><li>distill 提炼</li><li>lexical 词汇的，与词汇或词语有关</li><li>semantic 语义的，与词语的含义或解释有关</li><li>syntactic 句法的，与句子结构有关</li><li>sentiment 情感，对某事物的态度</li><li>polysemy 一词多义</li><li>gloss 词义, from dictionary，词典中对词语含义的解释</li><li>synonymy 同义词</li><li>antonymy 反义词</li><li>hypernymy 上义词, is-a，是一个更一般的词</li><li>hyponymy 一个更具体的词</li><li>meronymy 下义词, is-part-of</li><li>spectrum 范围</li><li>conference 共指，在文本中指代同一实体</li><li>anaphora 指代，一种语言现象，代替先前提到的词</li><li>utterence 话语</li><li>utter 说，发出声音</li><li>tedious 冗长的工作，乏味，枯燥</li><li>versality 可以在多种不同的情况和环境中使用，具有很高的适应性和灵活性</li><li>continuation 相连</li><li>patch-based 基于块的</li><li>interpretability 可解释性，白盒</li><li>explainability 可解释性，黑盒</li><li>monolingual 只使用一种语言的情况或者系统</li><li>sinusoidal 正弦的</li><li>proximal 接近的</li><li>miscellaneous 混杂的</li><li>antecedent 先行词, Trump</li><li>anaphor 指代词, he</li><li>pronominal 代词的</li><li>adjective 形容词</li><li>factoid 事实</li><li>intent 意图</li><li>clause 子句</li><li>toxicity 有毒</li><li>insult 侮辱</li><li>humiliation 羞辱</li><li>altered 改变</li><li>conjunction 连接词</li><li>conform 符合</li><li>genre 风格</li><li>spurious 伪造的</li><li>occurrence 出现</li><li>maginalisation 边缘化</li><li>nuance 细微差别</li></ul><h2 id=information-bottleneck>Information Bottleneck</h2><p>信息瓶颈问题是指在机器学习模型中，模型在尝试压缩输入数据的同时，还要尽可能保留与目标输出相关的信息。这是一个权衡问题，因为模型需要找到一个平衡点，既能有效地压缩数据，又能保留足够的信息来进行准确的预测。</p></section><footer class=article-footer><section class=article-tags><a href=/aquamega/tags/24s1/>24s1</a>
<a href=/aquamega/tags/ai/>AI</a></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/aquamega/p/lexical-semantics-and-distributional-semantics/><div class=article-details><h2 class=article-title>Lexical Semantics and Distributional Semantics</h2></div></a></article><article><a href=/aquamega/p/neual-networks/><div class=article-details><h2 class=article-title>Neual Networks</h2></div></a></article><article><a href=/aquamega/p/part-of-speech-tagging/><div class=article-details><h2 class=article-title>Part-of-Speech Tagging</h2></div></a></article><article><a href=/aquamega/p/hidden-markov-model/><div class=article-details><h2 class=article-title>Hidden Markov Model</h2></div></a></article><article><a href=/aquamega/p/n-gram-language-model/><div class=article-details><h2 class=article-title>N-gram Language Model</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2024 Dale的水硕日记</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.26.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/aquamega/ts/main.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>
<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>24s1 on Aqua Mega</title>
    <link>http://localhost:1313/aquamega/tags/24s1/</link>
    <description>Recent content in 24s1 on Aqua Mega</description>
    <image>
      <title>Aqua Mega</title>
      <url>https://github.com/shyu216.png</url>
      <link>https://github.com/shyu216.png</link>
    </image>
    <generator>Hugo -- 0.125.4</generator>
    <language>en</language>
    <lastBuildDate>Fri, 26 Apr 2024 14:56:11 +1000</lastBuildDate>
    <atom:link href="http://localhost:1313/aquamega/tags/24s1/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Geom90008</title>
      <link>http://localhost:1313/aquamega/course/geom90008/</link>
      <pubDate>Fri, 26 Apr 2024 14:56:11 +1000</pubDate>
      <guid>http://localhost:1313/aquamega/course/geom90008/</guid>
      <description>Spatial Data Management Course notebook: https://tomkom.pages.gitlab.unimelb.edu.au/spatialdatamanagement/.
Goal: Learn Postgre(pgAdmin 4) and GIS(QGIS). Help staff with herbarium data.
Vocabs scope creep: 任务蔓延 schema: 数据库的结构 query: 查询 ACID: Atomicity 原子性, Consistency 一致性, Isolation 隔离性, Durability 持久性 waterfall: 瀑布模型, 一次性完成所有工作 agile: 敏捷开发, 分阶段完成工作 ERD/ERM: Entity Relationship Diagram/Model, 实体关系图/模型 entity, attribute, relationship: 实体, 属性, 关系 location: space and time position: reference to a coordinate system 地理學第一定律: 所有事物都與其他事物相關, 但是近處的事物比遠處的事物更相關 longitude: 经度 latitude: 纬度 altitude: 海拔 wgs84: 地球坐标系, 经典的经纬度 polynomial: 多项式 ployline: 折线 polygon: 多边形 vertex: 顶点 vector: 向量 raster: 栅格 sphere: 球体 spheroid: 椭球体 Ideas 因为板块漂移, 会导致地理坐标系的变化 </description>
    </item>
    <item>
      <title>Comp90042</title>
      <link>http://localhost:1313/aquamega/course/comp90042/</link>
      <pubDate>Fri, 26 Apr 2024 14:56:05 +1000</pubDate>
      <guid>http://localhost:1313/aquamega/course/comp90042/</guid>
      <description>Natural Language Processing Preprocessing Sentence segmentation Tokenization, subword tokenization Word normalization Inflectional vs derivational morphology Lemmatization vs stemming Stopword removal N-gram Language Model Derivation Smoothing techniques Add-k Absolute discounting Katz backoff Kneser-Ney smoothing Interpolation Text Classification Build a classifier Task Topic classification Sentiment analysis Native language identification Algorithms Naive Bayes, logistic regression, SVM kNN, neural networks Bias vs variance：欠拟合under和过拟合over的取舍 Evaluation Precision, recall, F1 Part of Speech Tagging English POS Closed vs open classes Tagsets Penn Treebank tagset Automatic taggers Rule-based Statistical Unigram, classifier-based, HMM Hidden Markov Model Probabilistic formulation: Emission &amp;amp; Transition Training Viterbi algorithm Generative vs discriminative models Feedforward Neural Network Formulation Tasks: Topic classifcation Language models POS tagging Word embeddings Convolutional networks Recurrent Neural Network Formulation RNN: language models LSTM: Functions of gates Variants Tasks: Text classification: sentiment analysis POS tagging Lexical Semantics Definition of word sense, gloss Lexical Relationship: Synonymy, antonymy, hypernymy, meronymy Structure of wordnet Word similarity Path lenght Depth information Information content Word sense unambiguation supervised, unsupervised Distributional Semantics Matrices: VSM, TF-IDF, word-word co-occurrence Association measures: PMI, PPMI Count-based method: SVM Neural method: skip-gram, CBOW Evaluation: Word similarity, analogy Contextual Representation Formulation with RNN ELMo BERT Objective Fine-tuning for downstream tasks Transformers Multi-head attention Second half:</description>
    </item>
    <item>
      <title>Comp90077</title>
      <link>http://localhost:1313/aquamega/course/comp90077/</link>
      <pubDate>Fri, 26 Apr 2024 14:55:58 +1000</pubDate>
      <guid>http://localhost:1313/aquamega/course/comp90077/</guid>
      <description>Advanced Algorithms and Data Structures Learn some advanced algorithms and data structures.
Treap
Admortized Analysis: Prepaid/Potential
Quake Heap
Splay Tree
Perfect Hashing/Cuckoo Hashing
Range Tree
Min Cut/Max Flow
Karger&amp;rsquo;s algorithm: 找最小割, 找多次取最优, 随机地找两个节点合并, 直到只剩下两个节点
Ford-Fulkerson algorithm: 最早的最大流算法, 重复地找增广路径, 直到找不到
Edmonds-Karp algorithm: 用BFS找增广路径, complexity更低
Hall&amp;rsquo;s theorem: 一个二分图存在完美匹配当且仅当对于每一个子集, 子集的大小大于等于子集的邻居的大小
Vocabs conservation node: 保守节点, a node that has the same flow in and out
residual graph: 残余图, a graph that represents the remaining capacity of each edge</description>
    </item>
    <item>
      <title>Comp90054</title>
      <link>http://localhost:1313/aquamega/course/comp90054/</link>
      <pubDate>Fri, 26 Apr 2024 14:55:43 +1000</pubDate>
      <guid>http://localhost:1313/aquamega/course/comp90054/</guid>
      <description>AI Planning for Autonomy classical planning (blind/heuristic): https://fai.cs.uni-saarland.de/hoffmann/papers/ki11.pdf PDDL relaxation reinforcement learning: https://gibberblot.github.io/rl-notes/index.html Vocabs acyclic 无环
systematics 系统的 / local 局部
heuristic 启发式
monotonic 单调
priority queue = min heap
conformant 符合的
policy 策略，map from state to action, denoted by $\pi$
negation 否定
precondition 前提条件
propositional 命题
predicate 谓词，return true/false
schema 模式，define somthing
misplace 放错
dominate 支配
corollary 推论
point-wise 逐点
pessimistic 悲观
benchmark 基准
novelty 新颖性
prune 修剪
velocity 速度</description>
    </item>
  </channel>
</rss>

<!doctype html><html lang=en dir=auto><head><script src="/aquamega/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=aquamega/livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Nlp | Aqua Mega</title>
<meta name=keywords content><meta name=description content="Dale的水硕记录"><meta name=author content="Dale"><link rel=canonical href=http://localhost:1313/aquamega/tags/nlp/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/aquamega/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/aquamega/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/aquamega/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/aquamega/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/aquamega/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/aquamega/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=http://localhost:1313/aquamega/tags/nlp/index.xml><link rel=alternate hreflang=en href=http://localhost:1313/aquamega/tags/nlp/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Nlp"><meta property="og:description" content="Dale的水硕记录"><meta property="og:type" content="website"><meta property="og:url" content="http://localhost:1313/aquamega/tags/nlp/"><meta property="og:image" content="https://github.com/shyu216.png"><meta property="og:site_name" content="Dale的水硕记录"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://github.com/shyu216.png"><meta name=twitter:title content="Nlp"><meta name=twitter:description content="Dale的水硕记录"></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/aquamega/ accesskey=h title="Dale的水硕记录 (Alt + H)"><img src=https://github.com/shyu216.png alt aria-label=logo height=35>Dale的水硕记录</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/aquamega/posts/ title=posts><span>posts</span></a></li><li><a href=http://localhost:1313/aquamega/categories/ title=categories><span>categories</span></a></li><li><a href=http://localhost:1313/aquamega/tags/ title=tags><span>tags</span></a></li><li><a href=https://github.com/shyu216 title=github><span>github</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=http://localhost:1313/aquamega/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/aquamega/tags/>Tags</a></div><h1>Nlp
<a href=/aquamega/tags/nlp/index.xml title=RSS aria-label=RSS><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Part-of-Speech Tagging</h2></header><div class=entry-content><p>Part-of-Speech(词类) Colourless green ideas sleep furiously.
Open Classes (Content Words) Noun Verb Adjective Adverb Closed Classes (Function Words) (Fixed number of words) Preposition Determiner Pronoun Conjunction Interjection Ambiguity: A word can have multiple meanings. A sentence can have multiple interpretations.
在自然语言处理（NLP）中，POS代表词性标注（Part-of-Speech Tagging）。词性标注是一种将每个词语与其语法范畴（即词性）相关联的过程。它是NLP中的一项基本任务，用于确定句子中每个单词的词类。
常见的词性包括名词、动词、形容词、副词、介词、代词、冠词、连词等。通过进行词性标注，可以帮助计算机理解句子的结构和含义，为其他NLP任务（如句法分析、语义分析和机器翻译等）提供基础。
以下是一个例子，展示了一句英文句子的词性标注示例：
句子：I love eating ice cream.
词性标注：PRON VERB VERB NOUN NOUN.
在这个例子中，“I"被标注为代词（PRON），“love"和"eating"被标注为动词（VERB），“ice"和"cream"被标注为名词（NOUN）。
词性标注可以通过使用基于规则的方法、基于统计的机器学习方法（如隐马尔可夫模型）或基于深度学习的方法（如循环神经网络和转换器模型）来实现。这个任务在NLP中具有广泛的应用，对于许多文本处理任务都是重要的预处理步骤。
NN（noun）名词：cat（猫）、book（书）、table（桌子） VB（verb）动词：run（跑）、eat（吃）、sleep（睡觉） JJ（adjective）形容词：big（大的）、happy（快乐的）、red（红色的） RB（adverb）副词：quickly（快速地）、well（好地）、very（非常） DT（determiner）限定词：the（定冠词）、this（这个）、some（一些） CD（cardinal number）基数词：one（一）、three（三）、ten（十） IN（preposition）介词：on（在…上）、with（和…一起）、at（在…处） PRP（personal pronoun）人称代词：I（我）、you（你）、he（他） MD（modal）情态动词：can（能够）、should（应该）、will（将会） CC（coordinating conjunction）并列连词：and（和）、but（但是）、or（或者） RP（particle）小品词：up（向上）、down（向下）、out（出去） WH（wh-pronoun）疑问代词：who（谁）、what（什么）、which（哪个） TO（to）不定式标记：to（去）、to（为了）、to（到） Penn Treebank 词性标记集 Penn Treebank 的词性标注集（POS tagset）是一种广泛使用的英文词性标注方法。...</p></div><footer class=entry-footer><span title='2024-05-28 03:56:05 +1000 AEST'>May 28, 2024</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;205 words&nbsp;·&nbsp;Dale</footer><a class=entry-link aria-label="post link to Part-of-Speech Tagging" href=http://localhost:1313/aquamega/nlp/pos/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Lexical Semantics and Distributional Semantics</h2></header><div class=entry-content><p>Lexical Semantics 词汇解释
Synonymy 同义词 Antonymy 反义词 Hypernymy 上义词 Meronymy 下义词 WordNet A lexical database of English.
Word Similarity 路径长度：在WordNet中，两个词之间的路径长度可以用来衡量它们的相似性。 深度信息：在WordNet中，词的深度（在词汇树中的位置）也可以用来衡量词的相似性。 信息内容：词的信息内容（在语料库中的频率）也可以用来衡量词的相似性。 Distributional Semantics 词汇和其上下文的共现信息</p></div><footer class=entry-footer><span title='2024-05-28 00:56:05 +1000 AEST'>May 28, 2024</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;25 words&nbsp;·&nbsp;Dale</footer><a class=entry-link aria-label="post link to Lexical Semantics and Distributional Semantics" href=http://localhost:1313/aquamega/nlp/semantics/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Neual Networks</h2></header><div class=entry-content><p>神经网络（Neural Network）是一种模拟人脑神经元工作方式的机器学习模型。它由大量的神经元（也称为节点或单元）组成，这些神经元按照一定的层次结构排列，包括输入层、隐藏层和输出层。
每个神经元接收来自上一层神经元的输入，然后通过一个激活函数（如 Sigmoid、ReLU 等）处理这些输入，得到一个输出，这个输出再传递给下一层的神经元。
神经网络的训练通常使用反向传播（Backpropagation）算法和梯度下降（Gradient Descent）算法。在训练过程中，神经网络通过不断调整神经元之间的连接权重，来最小化预测值和真实值之间的差异。
神经网络可以处理非线性问题，适用于各种复杂的机器学习任务，如图像识别、语音识别、自然语言处理等。但是，神经网络的训练需要大量的数据和计算资源，而且模型的解释性较差，这是它的一些挑战。
A Neural Network is a machine learning model that simulates the way neurons in the human brain work. It consists of a large number of neurons (also known as nodes or units) arranged in a certain hierarchical structure, including input layers, hidden layers, and output layers.
Each neuron receives input from the neurons in the previous layer, then processes these inputs through an activation function (such as Sigmoid, ReLU, etc....</p></div><footer class=entry-footer><span title='2024-05-28 00:56:05 +1000 AEST'>May 28, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;231 words&nbsp;·&nbsp;Dale</footer><a class=entry-link aria-label="post link to Neual Networks" href=http://localhost:1313/aquamega/nlp/nn/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Hidden Markov Model</h2></header><div class=entry-content><p>w：word t：tag emission probability: $P(w|t)$ 从tag到word的概率 transition probability: $P(t|t')$ 从上一个tag到当前tag的概率 Viterbi Algorithm 从最开始算起，每个tag的概率是由前一个tag的概率和从前一个tag到当前tag的概率相乘得到的。
$\hat{t} = \arg\max_{t} \prod_{i=1}^{n} P(w_i|t)P(t|t')$, $t'$是前一个tag, $\hat{t}$是当前的估计值。
Generative vs Discriminative Tagger HMM是generative model，可以用来生成数据，无监督的学习。 discriminative model例如CRF，需要有监督的数据，可以学到更丰富的特征，大多数deep learning的模型都是discriminative model。</p></div><footer class=entry-footer><span title='2024-05-27 03:56:05 +1000 AEST'>May 27, 2024</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;30 words&nbsp;·&nbsp;Dale</footer><a class=entry-link aria-label="post link to Hidden Markov Model" href=http://localhost:1313/aquamega/nlp/hmm/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Text Classification</h2></header><div class=entry-content><p>Topic classification Sentiment analysis Native language identification Natual language inference Automatic fact-checking Paraphrase Topic Classification Motivation: library science, information retrieval, etc. Classes: topic categories Features: bag-of-words, n-grams, etc. Corpus: reuters news corpus, pubmed abstracts, tweets with hashtags Sentiment Analysis Motivation: opinion mining, business analytics Classes: positive, negative, neutral Features: n-grams, polarity lexicons, etc. Corpus: movie reviews, SEMEVAL twitter polarity dataset Native Language Identification Motivation: forensic linguistics, educational applications Classes: native languages Features: character n-grams, syntactic features (POS), phonological features Corpus: TOEFL/IELTS essays Natural Language Inference (textual entailment 文本蕴含) Motivation: language understanding Classes: entailment, contradiction, neutral Features: word overlap, length difference, etc....</p></div><footer class=entry-footer><span title='2024-05-27 02:56:05 +1000 AEST'>May 27, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;306 words&nbsp;·&nbsp;Dale</footer><a class=entry-link aria-label="post link to Text Classification" href=http://localhost:1313/aquamega/nlp/classification/></a></article><footer class=page-footer><nav class=pagination><a class=next href=http://localhost:1313/aquamega/tags/nlp/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/aquamega/>Aqua Mega</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
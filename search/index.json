[{"content":"Linear Program 最大流问题可以被表述为一个线性规划问题。线性规划是一种优化问题，目标是在一组线性约束条件下最大化或最小化一个线性目标函数。\n对于最大流问题，我们可以定义以下的线性规划模型：\n变量：对于每条边 e，我们定义一个变量 f(e)，表示边 e 的流量。\n目标函数：我们的目标是最大化从源点 s 到汇点 t 的总流量，即最大化 ∑f(e)，其中求和是对所有从 s 出发的边 e 进行的。\n约束条件：我们有两种类型的约束条件：\n容量约束：对于每条边 e，我们有 f(e) ≤ c(e)，其中 c(e) 是边 e 的容量。\n流量守恒约束：对于图中的每个非源非汇节点 v，我们有 ∑f(e_in) = ∑f(e_out)，其中 e_in 是进入节点 v 的边，e_out 是离开节点 v 的边。\n以下是对应的线性规划模型：\n1 2 3 4 5 maximize ∑f(e) for all e from s subject to f(e) ≤ c(e) for all e ∑f(e_in) = ∑f(e_out) for all v ≠ s, t f(e) ≥ 0 for all e 这个模型可以使用各种线性规划算法来解决，例如单纯形法（Simplex Method）或内点法（Interior Point Method）。\nVertex Cover 顶点覆盖（Vertex Cover）是图论中的一个重要概念。\n在一个图中，顶点覆盖是一个顶点的集合，这个集合的特性是图中的每一条边至少有一个端点在这个集合中。换句话说，如果你从这个集合中选出一个顶点，你可以覆盖到至少一条边。\n例如，考虑一个简单的图，它有四个顶点（A, B, C, D）和四条边（AB, BC, CD, DA）。在这个图中，{A, B, C, D} 是一个顶点覆盖，因为每一条边都至少有一个端点在这个集合中。同样，{A, C} 或者 {B, D} 也是顶点覆盖。\n顶点覆盖问题是寻找一个最小的顶点覆盖，也就是包含最少顶点的覆盖。这是一个 NP 完全问题，意味着没有已知的多项式时间算法可以解决所有的顶点覆盖问题。然而，有一些启发式算法和近似算法可以在实际中有效地解决顶点覆盖问题，例如贪心算法。\nMax Matching for Factor 2 Approximation 最大匹配（Max Matching）是图论中的一个重要概念。在一个图中，一个匹配是一个边的集合，其中每个顶点最多与一条边相连。最大匹配是一个具有最大边数的匹配。\n一个简单的近似算法是找到一个最大匹配，然后将匹配中的每条边的两个端点都加入顶点覆盖。这个算法的解至多是最优解的两倍。\n这个算法的正确性可以通过以下两点来证明：\n它是一个覆盖：假设不是，那么存在一条没有被覆盖的边。但是，这条边应该被加入到最大匹配中，因为它不与当前匹配中的任何边共享端点。这就产生了矛盾，所以这个假设是错误的，这个集合确实是一个覆盖。\n它至多是最优解的两倍：因为每条匹配的边都贡献了两个顶点到覆盖中，所以覆盖的大小是匹配的大小的两倍。而最大匹配的大小至少是任何顶点覆盖的大小（因为每个覆盖的顶点至多可以覆盖一条匹配的边），所以这个覆盖的大小至多是最优覆盖的大小的两倍。\nLP Relaxation for Vertex Cover 在线性规划版本的顶点覆盖问题中，我们的目标是找到一组𝑦𝑣的值（对应每个顶点𝑣），使得对于每条边(u,v)，都有𝑦𝑢 + 𝑦𝑣 ≥ 1，并且∑𝑦𝑣尽可能小。\n当𝑦𝑣的值小于0.5时，这并不意味着会违反𝑦𝑢 + 𝑦𝑣 ≥ 1的条件。因为即使一个顶点的𝑦值小于0.5，只要它连接的另一个顶点的𝑦值大于0.5，那么这条边仍然可以被覆盖。换句话说，𝑦𝑢 + 𝑦𝑣 ≥ 1的条件是针对每条边来说的，而不是针对每个顶点。\n所以，即使𝑦𝑣的值小于0.5，只要找到的这组𝑦𝑣的值满足对于每条边(u,v)，都有𝑦𝑢 + 𝑦𝑣 ≥ 1，那么就不会违反这个条件。\n这是一个关于图论中顶点覆盖问题的线性规划近似解法的问题。这个方法的基本步骤如下：\n写出顶点覆盖问题的线性规划（LP）形式。 在多项式时间内解决这个LP问题。 在多项式时间内对LP解进行四舍五入，损失因子为2。 这个方法被称为2-近似解法，原因如下：\n顶点覆盖问题的目标是找到一个最小的顶点集合，使得图中的每条边都至少与集合中的一个顶点相连。在LP解法中，每个顶点被赋予一个0到1之间的值，表示这个顶点被选中的可能性。然后，我们将这些值四舍五入到最近的整数，得到一个顶点覆盖的近似解。\n这个方法的近似比例为2，是因为四舍五入操作可能会导致选中的顶点数目增加。具体来说，如果一个顶点在LP解中的值为0.5，那么在四舍五入后，这个顶点可能会被选中，从而增加了顶点覆盖的大小。然而，由于每个顶点的值都不会超过1，所以这个增加的数量最多不会超过原始LP解的两倍。因此，这个方法被称为2-近似解法。\nSet Cover 集合覆盖（Set Cover）是计算机科学中的一个经典问题，它是 NP 完全问题的一个例子。\n给定一个有限集合 U 和 U 的若干子集 S1, S2, \u0026hellip;, Sn，集合覆盖问题是要找到最小的子集合的集合，使得这些子集合的并集等于 U。\n例如，如果 U = {1, 2, 3, 4, 5}，S1 = {1, 2, 3}，S2 = {2, 4}，S3 = {3, 4, 5}，那么 {S1, S3} 就是一个集合覆盖，因为 S1 和 S3 的并集等于 U。\n集合覆盖问题在许多实际问题中都有应用，例如在无线网络设计、数据库系统、信息检索等领域。在这些问题中，我们通常希望找到一个最小的集合覆盖，以最小化成本或资源使用。\n集合覆盖问题是 NP 完全问题，这意味着没有已知的多项式时间算法可以解决所有的集合覆盖问题。然而，有一些启发式算法和近似算法可以在实际中有效地解决集合覆盖问题，例如贪心算法。\nLP Relaxation for Set Cover 这是关于集合覆盖问题的贪心算法近似解法的问题。集合覆盖问题是一个NP完全问题，其决策版本的目标是找到一个最小的子集合，使得这些子集合的并集等于全集。\n贪心算法的基本步骤如下：\n初始化一个空的解决方案。 在每一步，选择一个对当前解决方案贡献最大的集合，将其添加到解决方案中。这里的\u0026quot;贡献\u0026quot;是指该集合包含的、在当前解决方案中尚未被覆盖的元素数量（如果是加权版本，则还需要除以集合的权重）。 重复第2步，直到全集被覆盖。 这个贪心算法的近似比例为1 + ln n，其中n是全集的元素数量。这是因为在每一步，我们总是选择贡献最大的集合，这保证了我们的解决方案不会比最优解差太多。具体来说，无论最优解需要多少个集合k，这个算法总是返回一个至多为k(1 + ln n)的解决方案。\n更严格的分析表明，这个算法的近似因子实际上是(ln n - ln ln n) + Θ(1)。这意味着，随着n的增大，这个算法的性能会逐渐接近最优解。\n然而，已经证明，除非P=NP，否则集合覆盖问题不能在1 - o(1) ⋅ ln n的范围内被近似。这意味着，我们不能期望有一个在多项式时间内运行的近似算法，其近似因子的增长速度比c ⋅ ln n慢，其中c \u0026lt; 1。\n这是关于贪心算法在集合覆盖问题中的近似比例证明的问题。证明的基本思路如下：\n假设最优解包含k个集合。在每一次贪心迭代中，未被覆盖的元素数量会减少一个因子1 - 1/k。这是因为我们总是选择贡献最大的集合，而这个集合至少包含了最优解中每个集合的平均贡献。\n由于我们开始时有n个未被覆盖的元素，所以在进行k ln n次迭代后，所有的元素都会被覆盖。这里的ln n是因为在每次迭代中，未被覆盖的元素数量都会减少一个因子1 - 1/k，所以需要ln n次迭代才能将这个数量减少到1以下。\n由于实际的迭代次数可能不是整数，所以我们需要向上取整，得到⌈k ln n⌉。这意味着，我们的解决方案的大小最多为最优解的1 + ln n倍。\n这个证明表明，贪心算法在集合覆盖问题中的近似比例为1 + ln n，这是一个对数级别的近似比例。这也解释了为什么这个算法被称为对数级别的贪心算法。\nDuality 线性规划的对偶性是一个非常重要的概念。对于每一个线性规划问题（称为原问题），都存在一个相关的线性规划问题（称为对偶问题）。原问题和对偶问题之间有一些非常有趣的关系。\n对偶问题的目标函数是原问题的约束条件的线性组合，反之亦然。\n对偶问题的解（对偶值）提供了原问题解（原值）的一个下界（如果是最大化问题）或上界（如果是最小化问题）。\n如果原问题和对偶问题都有解（即它们是可行的），那么它们的最优解是相等的。这就是所谓的弱对偶性。如果原问题是无界的，那么对偶问题是不可行的，反之亦然。\n在某些条件下（例如，如果原问题和对偶问题都满足某些正则性条件），我们可以保证强对偶性，即原问题的任何可行解和对偶问题的任何可行解都有相同的目标函数值。\n这些对偶性质在解决线性规划问题时非常有用。例如，它们可以用来检验解的最优性，提供解的上下界，以及通过解对偶问题来更有效地解原问题。\n近似算法 近似算法是一种在有限时间内找到最优解的近似解的算法。在许多情况下，找到最优解可能需要非常长的时间，或者甚至是不可能的。在这种情况下，近似算法可以提供一个可接受的、接近最优的解。近似算法的一个主要优点是它们通常可以在多项式时间内运行，这使得它们在处理大规模问题时非常有用。\nLPs 作为有效的松弛 在优化问题中，松弛是一种将一个难以解决的问题转化为一个更容易解决的问题的技术。线性规划可以作为一种有效的松弛技术，将一些难以直接解决的问题转化为线性规划问题。通过这种方式，我们可以利用线性规划的强大求解能力来解决更复杂的问题。\n舍入、对偶拟合、原始-对偶方法 这些都是处理线性规划问题的技术。舍入是一种将连续解转化为离散解的方法；对偶拟合是一种通过解对偶问题来找到原问题解的方法；原始-对偶方法是一种同时解原问题和对偶问题的方法。这些技术都是为了在实际应用中更好地解决线性规划问题。\n","date":"2024-06-15T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/linear-programming/","title":"Linear Programming"},{"content":" 桶排序是一种排序算法，适用于当数据范围已知的情况。 排序/构建的时间复杂度：O(n)。这表示我们需要遍历每个元素，并将其放入相应的桶中。在最好和平均的情况下，如果元素均匀分布，那么桶排序的时间复杂度可以达到 O(n)。 查找的时间复杂度：O(1)。这表示我们可以直接通过元素的值来确定它在哪个桶中，然后在该桶中进行查找。如果每个桶的大小都很小（例如，大小为1），那么查找操作的时间复杂度可以视为常数时间 O(1)。 ","date":"2024-06-13T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/bucket/","title":"Bucket"},{"content":" 喜欢很少更新数据的情况，static dictionary search Univeral Hashing 通用哈希函数族具有以下性质：\n如果我们从哈希函数族 H 中均匀随机地选择一个哈希函数 h，那么对于 U 中的每一对不同的元素 x 和 y，x 和 y 在 h 下发生冲突的概率满足：\n$Pr_{h \\in H}[h(x) = h(y)] \\leq \\frac{1}{m}$\n这里，$Pr_{h \\in H}[h(x) = h(y)]$ 表示在哈希函数族 H 中选择的哈希函数 h 使得 x 和 y 发生冲突的概率，m 是哈希表的大小。\n给定一个包含 n 个元素的集合 S，我们从一个通用的函数族 H 中均匀随机地选择一个哈希函数 h，我们可以达到以下效果：\n预处理时间：最坏情况下为 O(n + m)； 空间消耗：最坏情况下为 O(n + m)； 查询时间：期望为 O(1 + n/m)。找到哈希值的时间为 O(1)，解决冲突的时间为 O(n/m)，比如遍历桶中元素，平均有n/m个。 如上所述，m 控制了空间消耗和期望查询时间之间的权衡。\n当 m = Θ(n) 时，空间消耗为 O(n)，期望查询时间为 O(1)。\nwhen $m = n$ 查询时间：O(1)，expected when $m = n^2$ 理论上此时碰撞期望小于1。\n预处理时间：O(n^2) 空间消耗：O(n^2) 查询时间：O(1)，worst case Perfect Hashing 两层的哈希表，第一层用于解决冲突，第二层用于存储数据。\n第一层m=n，第二层m=n^2。\n预处理时间：O(n) 空间消耗：O(n) 查询时间：O(1)，worst case Cuckoo Hashing 布谷鸟，k个表，插值时，如果发生冲突，就把原来的元素挤出去，直到找到空位。\n插入时间：期望为 O(1) 删除时间：最坏情况下为 O(1) 查询时间：最坏情况下为 O(1) 构建时间：期望为 O(n) 空间消耗：最坏情况下为 O(n) ","date":"2024-06-13T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/hash/","title":"Hash"},{"content":" 数据在leaf，整个堆用priority维护，跟实际数据无关 Insertion: O(1) expected, O(log n) worst case Search: N/A (or O(n) if heap is traversed) Decrease Key: O(1) expected, O(n) worst case Deletion (Delete Min): O(log n) expected, O(n) worst case Quake Heaps 是一种优先队列数据结构，它在处理动态集合中的元素和执行相关操作（如插入、删除、查找最小元素等）时，提供了良好的时间复杂性。Quake Heaps 的一个关键特性是它们的删除操作的摊还时间复杂度为 $O(\\log n)$，这使得它们在需要频繁删除操作的应用中非常有用。\n以下是一些可能使用 Quake Heaps 的应用：\n图算法：许多图算法，如 Dijkstra 的最短路径算法和 Prim 的最小生成树算法，需要使用优先队列来高效地找到下一个要处理的节点。在这些算法中，Quake Heaps 可以用来提高性能。\n事件驱动的模拟：在事件驱动的模拟中，事件是按照它们发生的时间顺序处理的。Quake Heaps 可以用来存储和检索这些事件，以确保它们按照正确的顺序被处理。\n任务调度：在任务调度问题中，我们需要根据任务的优先级来决定执行顺序。Quake Heaps 可以用来存储和检索任务，以确保优先级最高的任务首先被执行。\n请注意，虽然 Quake Heaps 在理论上有很好的性能，但在实践中，由于它们的实现复杂性，可能会选择其他更简单但性能稍差的数据结构，如 Fibonacci heaps 或 binary heaps。\nTournament Trees Quake Heaps 是基于 Tournament Trees 的一种改进。Tournament Trees 是一种完全二叉树，其中每个节点都包含一个元素，并且树的叶子节点是输入元素。在 Tournament Trees 中，每个节点都存储了其子树中的最小元素。这使得 Tournament Trees 可以用来高效地找到最小元素。\nPointers P即T的最后一层，每个节点都是一个元素。\n元素指针：在优先队列 P 中，每个元素都保持一个指向 Tournament Tree T 中概念上存储其优先级的最高节点（即，高度最大的节点）的指针。\n节点指针：在 Tournament Tree T 中，每个节点 u 都有一个指向优先队列 P 中的元素的指针，u 概念上存储了该元素的优先级。\nNode-Number-at-Height Invariant 在 Quake Heaps 中，有一个重要的不变性，即“高度 h 处的节点数目”不变性。\n有一个constant $c$，上一层的节点数目是下一层的节点数目的 $c$ 倍。这个不变性保证了 Quake Heaps 的高效性。\n1 2 3 4 5 6 c = 0.6 n5 = 1 n4 = 3 n3 = 5 n2 = 9 n1 = 15 $n_{h+1} \\leq c \\cdot n_h$\nlog n 最后一层至多n个 每层会少c倍 层数至多$\\log_{1/c} n$ Operations Link 将两个 Tournament Trees 连接成一个更大的 Tournament Tree。这个操作的时间复杂度是 $O(1)$。\n条件：两个 Tournament Trees 的高度相同。\nCut 切根和较大的子节点。这个操作的时间复杂度是 $O(1)$。\nInsert 直接插入，建个新树。这个操作的时间复杂度是 $O(1)$。\nDecrease Key 降低一个元素的优先级。把它的值减小，找到它指的树中的节点，然后cut。这个操作的时间复杂度是 $O(1)$。\nDelete Min 找到最小的元素，删掉整个path。通常先经过decrease key，使目标数据有最小priority，操作更方便。要是有same height，link起来。\n这个操作的时间复杂度是 $O(\\log n)$，可以用admortized analysis证明。\n跟树的数量，和path的长度有关。 找到具有最小键值的元素。 有T个树，需T步 删除这个元素。 如path长L，有L步 1和2共T+L 同一高度的树合并。while loop T-1个其他树，切掉path后有L个新树，共T+L-1步 仅需T+L-2个合并，因为至少剩下一个树 $T^{(1)} \\leq 2h^{(0)}_{max}$，合并后的树的数量小于等于合并前最高的树的高度的2倍 保持不变性。 只会删node，而不加，把不符的高层整层删掉，$\\Delta N \u0026lt; 0$ 新增的树不会比新的最高层的node多，$\\Delta T \\leq n^{(0)}_h$ 只会删坏节点，而不加，按层删的，所以就算往上一层h+1坏节点。这一层的节点数是两倍上一层的好节点和一倍上一层的坏节点，所以$n_h = 2(n_{h+1} - b_{h+1}) + 1*b_{h+1}$ Admortized Analysis N个元素，T个树，B个坏节点（只有一个孩子）\n$\\Phi = N + 3T + \\frac{3}{2\\alpha -1}B$\n$T^{(1)} \\leq 2h^{(0)}_{max}$ 每种高度的树最多有一个，不然就被合并了 合并后的高度至多是原来的两倍 合并前至多有$h^{(0)}{max}$种高度的树，每种合并一次，最后高度会是$2h^{(0)}{max}$ ","date":"2024-06-13T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/quake-heap/","title":"Quake Heap"},{"content":" 用于范围查询（一次多个值） 对于二维数据：\n构建时间：O(n log n) 空间消耗：O(n log n)，log n层，每层至多n个 查询时间：O(k + log n)，其中 k 是报告的点的数量。 查询算法 给定一个查询范围 Q = [a1, b1] × [a2, b2]，我们可以通过以下步骤报告所有在 P ∩ Q 中的点：\n在 Tx 中找到 a\u0026rsquo; = succ(a1) 和 b\u0026rsquo; = pred(b1)； 让 usplit = LCA(a\u0026rsquo;, b\u0026rsquo;)，La1 是从 usplit 的左孩子到 a\u0026rsquo; 的路径，Lb1 是从 usplit 的右孩子到 b\u0026rsquo; 的路径； 如果 usplit ∈ Q，报告 usplit； 对于路径 La1 上的每个节点 u： 如果 u ∈ Q，报告 u； 如果 a\u0026rsquo; ≤ u.x，那么报告 u 的右子树中所有 y 坐标在 [a2, b2] 范围内的点； 对于路径 Lb1 上的每个节点 u： 如果 u ∈ Q，报告 u； 如果 b\u0026rsquo; ≥ u.x，那么报告 u 的左子树中所有 y 坐标在 [a2, b2] 范围内的点。 这个算法的基本思想是首先在 x 轴上找到查询范围的边界，然后在这个范围内的每个节点上进行 y 轴的范围搜索。这是一个有效的方法，因为它可以利用二维空间的结构来减少搜索的复杂性。\n在开始时，我们承诺可以在 $O(k + \\log n)$ 时间内完成二维轴平行矩形范围查询。然而，当前的查询成本是 $O(k + \\log^2 n)$，这违反了我们的承诺。\n为了将查询时间从 $O(k + \\log^2 n)$ 降低到 $O(k + \\log n)$，我们需要应用一种称为分数级联（Fractional Cascading）的技术。\n分数级联是一种用于优化多层次数据结构查询的技术。通过在每一层都保留一部分信息，我们可以避免在每一层都进行完全的二分查找，从而将查询时间从 $\\log^2 n$ 降低到 $\\log n$。这种技术在处理二维范围查询、最近邻查询等问题时非常有用。\nFractional Cascading 分数级联是一种技术，用于加速范围查询。它通过在不同层次的数据结构之间共享信息来减少查询时间。\nsucc和pred指针，指向下一层的元素。\n这段文字是在描述如何通过应用分数级联（Fractional Cascading）技术来优化二维轴平行矩形范围查询的时间复杂度。\n基于上述观察，我们可以将所有的次级树替换为排序数组，并应用分数级联技术，以将 $O(k + \\log^2 n)$ 的查询时间降低到 $O(\\log n + k + \\log n) = O(k + \\log n)$。\n分数级联的基本思想是在每一层的数据结构中保留一部分信息，以便在查询时可以快速定位到下一层的查询位置，从而避免在每一层都进行完全的二分查找。在这个上下文中，我们将次级树替换为排序数组，然后在每个数组中保留一部分信息，以便在查询时可以快速定位到下一个数组的查询位置。\n这种方法可以将查询时间从 $O(k + \\log^2 n)$ 降低到 $O(k + \\log n)$，从而满足我们在开始时的承诺。\n实现 在范围树中实现分数级联（Fractional Cascading）可以有效地减少查询时间。以下是一个简单的实现步骤：\n在构建范围树时，每个节点都存储其子节点的最大和最小值。这样，我们可以快速确定一个查询范围是否与一个子树有交集。\n对于每个节点，我们在其左右子节点中存储一个指向其父节点的指针。这样，我们可以从一个子节点快速跳转到其父节点。\n当我们进行范围查询时，我们首先在树的根节点开始。我们检查查询范围是否与左右子树有交集。如果有交集，我们就跟踪这个子树，并更新查询范围以排除已经检查过的部分。\n当我们跟踪一个子树时，我们使用存储在节点中的指针，快速跳转到其父节点。然后，我们重复步骤3，直到我们检查了所有与查询范围有交集的子树。\n最后，我们返回所有在查询范围内的节点。\n通过这种方式，我们可以在 O(log n + k) 的时间内完成查询，其中 n 是树中的节点数量，k 是查询返回的节点数量。这比没有使用分数级联的 O(n log n + k) 快得多。\n","date":"2024-06-13T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/range-search/","title":"Range Search"},{"content":" 越常访问，越靠近root 一种balanced BST，但不保证平衡 Insertion: O(log n) expected, O(n) worst case Search: O(log n) expected, O(n) worst case Deletion: O(log n) expected, O(n) worst case Zig-Zig and Zag-Zag left-left/right-right turns to right-right/left-left\nZig-Zag and Zag-Zig turns to middle\nZig and Zag just swap\nSuccessful-search-only sequence \u0026ldquo;Successful-search-only sequence\u0026rdquo; 是一种特定的操作序列，其中只包含成功的搜索操作。在这种序列中，所有的搜索操作都能找到它们正在寻找的元素。\n这种操作序列在分析某些数据结构的性能时非常有用。例如，当我们分析哈希表的性能时，我们可能会考虑最坏情况下的操作序列，其中包含大量的失败的搜索操作。然而，在实际应用中，失败的搜索操作可能非常少，因此，考虑 \u0026ldquo;successful-search-only sequence\u0026rdquo; 可能会给出更准确的性能分析。\n在 \u0026ldquo;successful-search-only sequence\u0026rdquo; 中，由于所有的搜索操作都是成功的，所以数据结构的性能主要取决于如何高效地存储和检索元素。因此，这种操作序列对于理解和优化数据结构的性能非常有用。\nInformation theory 信息理论能够帮助我们理解数据结构的性能。在信息理论中，我们可以使用熵来衡量数据的不确定性。熵越高，数据的不确定性就越大。\n它可以用来界定最优的成本界限。\n","date":"2024-06-13T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/splay-tree/","title":"Splay Tree"},{"content":"$\\sum_{i=1}^{m} cost(\\sigma_i) \\leq \\sum_{i=1}^{m} a(\\sigma_i)$\n摊还分析是一种分析数据结构操作成本的方法，它将操作的成本在一系列操作中进行平均，而不是单独考虑每个操作。\n我们的目标是证明对于任何一系列的动态数组操作 $\\sigma_1,\u0026hellip;,\\sigma_m$，如果每个操作的摊还成本 $a(\\sigma_i)$ 是 $O(1)$（即常数时间），那么整体的成本不等式 $\\sum_{i=1}^{m} cost(\\sigma_i) \\leq \\sum_{i=1}^{m} a(\\sigma_i)$ 就能成立。\n这个不等式的含义是，所有操作的实际总成本（左边的部分）不会超过所有操作的摊还总成本（右边的部分）。这是摊还分析的一个重要性质，它保证了我们的摊还成本确实反映了实际的成本。\nPrepaid $\\sum_{i=1}^{m} a(\\sigma_i) = \\sum_{i=1}^{m} cost(\\sigma_i) + \\sum_{i=1}^{m} \\Beta$\nwhere $\\Beta \\geq 0$ (总是有余额)\n\u0026ldquo;Prepaid\u0026rdquo;（预付）是摊还分析中的一个概念，它描述的是一种策略，即在执行一些高成本的操作之前，先执行一些低成本的操作来“预付”高成本操作的部分或全部成本。\n例如，考虑一个动态数组的插入操作。当数组满时，我们需要分配一个新的、更大的数组，并将旧数组中的所有元素复制到新数组中。这个操作的成本是线性的。然而，如果我们将这个成本均摊到之前的每次插入操作上，那么每次插入操作的摊还成本就是常数的。这就是预付策略的一个例子：我们通过每次插入操作“预付”一部分成本，来避免在数组满时一次性支付所有的成本。\n预付策略的一个关键思想是，我们可以将一些高成本的操作的成本分摊到多个低成本的操作上，从而使得所有操作的摊还成本都保持在一个可接受的范围内。这种策略在设计和分析高效的数据结构和算法时非常有用。\nPotential Function $\\sum_{i=1}^{m} a(\\sigma_i) = \\sum_{i=1}^{m} cost(\\sigma_i) + \\sum_{i=1}^{m} \\Phi(D_i) - \\Phi(D_0)$\nwhere $\\Phi(D_0)$ = 0, $\\Phi(D_i) \\geq 0$（不能超出势能）\n在摊还分析中，我们经常使用势能方法来证明摊还成本。下面是一个经典的例子：动态数组的插入操作。\n动态数组是一种可以动态增长和缩小的数组。当我们向动态数组中插入元素时，如果数组已满，我们需要创建一个新的、更大的数组，然后将旧数组中的所有元素复制到新数组中。这个操作的成本是线性的。然而，如果我们使用摊还分析，我们可以证明每次插入操作的摊还成本是常数的。\n我们定义势能函数 $\\Phi$ 为数组的当前大小减去数组中的元素数量。当我们插入一个元素时，有两种情况：\n如果数组没有满，我们只需要在数组的末尾添加一个元素。这个操作的实际成本是 $1$，势能的变化是 $-1$，所以摊还成本是 $1 - (-1) = 2$。\n如果数组已满，我们需要创建一个新的、大小为 $2n$ 的数组，并将 $n$ 个元素复制到新数组中。这个操作的实际成本是 $n+1$，势能的变化是 $n - n = 0$，所以摊还成本是 $n+1 - 0 = n+1$。\n在第二种情况中，摊还成本看起来是线性的。然而，这种情况只会发生在插入操作的数量是当前数组大小的整数倍时。在大多数情况下，我们处于第一种情况，摊还成本是常数的。因此，我们可以说插入操作的摊还成本是常数的，即 $a(\\sigma_i) \\in O(1)$。\n","date":"2024-06-11T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/admortized-analysis/","title":"Admortized Analysis"},{"content":"Big-O Notation $$ f(n) \\in O(g(n)) \\text{ iff } \\exists c_1, c_2, \\forall n \u0026gt; c_2, f(n) \\leq c_1 \\cdot g(n)$$\n$O(\\log n) \\subset O(n^k) \\subset O(2^n)$ 求证？设新方程，用相除或相减把不等式移到同一边，然后证明单调性，且大于1或大于0，取得$c_1, c_2$的值。\n","date":"2024-06-11T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/log-nn2n%E7%9A%84%E5%85%B3%E7%B3%BB/","title":"log n，n，2^n的关系"},{"content":"数学归纳法（Mathematical Induction）是一种常用的数学证明技巧（Mathematical Proof Technique），主要用于证明一系列数字或对象具有某种性质。它的基本步骤如下：\n基础步骤（Base Step）：证明性质对于第一个元素（通常是1或0）成立。 归纳步骤（Inductive Step）：假设性质对于某个元素 n 成立，然后证明这个性质对于元素 n+1 也成立。 举个例子，我们可以用数学归纳法证明所有的自然数之和的公式：\n1 + 2 + 3 + \u0026hellip; + n = n*(n+1)/2\n证明如下：\n基础步骤：对于 n=1，左边是1，右边也是1，所以公式成立。 归纳步骤：假设公式对于 n=k 成立，即 1 + 2 + 3 + \u0026hellip; + k = k*(k+1)/2，我们需要证明公式对于 n=k+1 也成立。即证明 1 + 2 + 3 + \u0026hellip; + k + (k+1) = (k+1)((k+1)+1)/2。将假设代入左边，我们得到 k(k+1)/2 + (k+1) = (k+1)*((k+1)+1)/2，简化后可以看到这个等式是成立的。 所以，我们用数学归纳法证明了所有的自然数之和的公式。\n","date":"2024-06-11T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/mathematical-induction/","title":"Mathematical Induction"},{"content":"请注意！本文是由公元2024年的GPT生成的，可能包含一些不准确的信息。\n最大流（Max-Flow）问题和最小割（Min-Cut）问题在网络流中是两个互相关联的问题，它们的关系通常被称为最大流-最小割定理（Max-Flow Min-Cut Theorem）。\n最大流-最小割定理是网络流中的一个基本定理，它指出了一个网络的最大流量和该网络的最小割的容量之间的关系。具体来说，对于任何网络，其最大流量等于其最小割的容量。\n在一个网络流图中，流量从源节点（source）流向汇节点（sink）。最大流问题就是要找到一种流的分配方式，使得从源节点到汇节点的总流量最大。\n割（cut）是将网络图分割成两部分的一种方式，其中一部分包含源节点，另一部分包含汇节点。割的容量（capacity）是从源节点部分到汇节点部分的所有边的容量之和。最小割问题就是要找到一种割的方式，使得割的容量最小。\nKarger\u0026rsquo;s Algorithm for Min Cut David Karger 的最小割算法是一种随机化算法，用于在无向图中找到最小割。这个算法基于一种称为“边收缩”（edge contraction）的操作。\n这个算法的期望运行时间是多项式的，但是它可能需要多次运行才能找到真正的最小割。为了提高找到最小割的概率，我们可以多次运行这个算法，并返回所有运行中找到的最小割。\nAdjacency list\n邻接列表是一种表示图的方法，它为图中的每个顶点维护一个列表，列出了从该顶点出发可以到达的所有顶点。在 Python 中，我们通常使用字典来实现邻接列表，其中键是顶点，值是一个列表，包含了所有连接到该顶点的顶点。邻接列表是一种空间效率高的数据结构，特别适合于稀疏图，即边的数量远小于顶点的数量的平方的图。\nUnion-Find\n并查集是一种用于处理不相交集合的数据结构。它支持两种操作：查找和合并。查找操作 Find(x) 用于找到包含元素 x 的集合的代表元素。合并操作 Merge(x, y) 用于将包含元素 x 和 y 的两个集合合并为一个集合。并查集的一个重要特性是，这两种操作的时间复杂度都接近于常数，这使得它在处理大规模数据时非常高效。\nGreedy Algorithm for Max Flow 初始化所有边的流量为0。 寻找一条从源点s到目标点t的路径，这条路径上的每一条边的流量都小于其容量。 沿着找到的这条路径尽可能多地增加流量，找到路径上剩余容量最小的边，然后增加这个量的流量。 我们重复以上步骤，直到无法找到满足条件的路径为止。\n无法保证最优。贪心算法可能会选择一条在当前看来可以增加最多流量的路径。然而，这可能会导致在后续的步骤中，无法找到新的路径来进一步增加流量。 Ford-Fulkerson Algorithm for Max Flow Ford-Fulkerson 算法是一种解决最大流问题的经典方法。这个算法的基本步骤如下：\n初始流设为零。 只要在残余网络中存在一条从源节点 s 到汇点 t 的路径，就执行以下操作： 寻找一条可以增加流量的路径。 更新流量和残余网络。 返回最后计算出的流量。 Proofs 在每一次迭代中，流量都是整数：这可以通过数学归纳法来证明。初始的流量是零，是一个整数。在每次迭代中，我们都在一条路径上增加整数的流量，所以流量始终是整数。\n在每次迭代中，流量增加了 KP：这可以通过观察源节点 s 和路径来证明。在每次迭代中，我们都在一条从 s 到 t 的路径上增加流量，所以总流量会增加。\n算法会在有限的步骤后停止（最多在 𝐶 = ∑(对所有边的容量𝑐求和) 迭代后）：这可以从前面的证明推断出来。因为每次迭代都会增加流量，而总流量受到网络容量的限制，所以算法一定会在有限的步骤后停止。\nRunning time Ford-Fulkerson（FF）算法的运行时间取决于多个因素，包括图的结构、边的容量以及选择增广路径的策略。在每次迭代中，算法需要在残余图中找到一条源节点s到目标节点t的路径，然后根据这条路径更新流量和残余图。\n每次迭代的时间复杂度为O(m)，其中m是图中的边的数量，原因如下：\n在残余图中找到一条s-t路径：这可以通过深度优先搜索（DFS）或广度优先搜索（BFS）来完成，时间复杂度为O(m)。\n更新流量和残余图：一旦找到了一条增广路径，我们需要遍历这条路径上的所有边，更新它们的流量和残余容量。这个过程的时间复杂度也为O(m)，因为一条路径上的边的数量最多为m。\n因此，每次迭代的时间复杂度为O(m)。然而，需要注意的是，FF算法的总运行时间并不是多项式时间，因为算法的迭代次数取决于最大流量，而这可能远大于图的大小。\n循环的次数最多是 C，其中 C 是图中所有边的容量之和。这是因为在每次循环中，我们至少增加一单位的流量，因此最多需要 C 次循环。\n因此，总的运行时间是 O(Cm)。而实际情况一般是线性时间。\nFlow vs Cut 在最大流最小割定理中，流等于割是因为在流网络中，流的大小受限于割的容量。这个定理告诉我们，任何流网络的最大流都等于其某个割的最小容量。\n这是因为：\n流的大小不能超过任何割的容量。这是因为割定义了从源点到汇点的所有可能的路径，流必须通过这些路径，因此不能超过割的容量。\n在最大流的情况下，存在一个割，其容量等于流的大小。这是因为当我们找到最大流时，我们已经找到了一种方式，使得所有从源点到汇点的路径都被充分利用，这就形成了一个割。\n在最大流最小割定理中，可达性（reachability）的概念是非常重要的。我们可以通过以下步骤使用可达性来证明这个定理：\n首先，我们找到流网络中的一个最大流。在这个流中，我们可以找到一个割，即一个将网络分割成两部分的边集，使得所有的流都从割的一边（源点所在的一边）流向另一边（汇点所在的一边）。\n然后，我们考虑在残余网络中从源点开始的可达性。在残余网络中，一个节点是可达的，如果存在一条从源点到该节点的路径，路径上的所有边在残余网络中都有正的容量。\n在最大流的情况下，汇点在残余网络中是不可达的，因为所有的流都已经达到了最大值，没有更多的容量可以从源点流向汇点。这意味着存在一个割，将可达的节点和不可达的节点分开，割的容量等于最大流的值。\n因此，我们证明了最大流等于最小割。这是因为我们找到了一个割，其容量等于最大流的值，而任何其他割的容量必须大于或等于这个值，因为流的大小不能超过割的容量。所以，这个割就是最小割，其容量（即最小割的值）等于最大流的值。\nFlow-Value Lemma 流量值引理（Flow-Value Lemma）是网络流问题中的一个重要概念，它描述了流入和流出一个节点的总流量之间的关系。\n流量值引理的内容如下：\n对于任何流网络中的节点 v（除了源点 s 和汇点 t），流入节点 v 的总流量等于流出节点 v 的总流量。这个性质也被称为流的守恒性质，因为它意味着除了源点和汇点之外，没有流量在任何节点处被创建或消失。\n数学上，这可以表示为：\n对于所有节点 v（v ≠ s, v ≠ t），∑{u ∈ V} f(u, v) = ∑{u ∈ V} f(v, u)\n其中 V 是节点的集合，f(u, v) 是从节点 u 到节点 v 的流量。\n这个引理是网络流问题中的基本性质，它是许多网络流算法，包括 Ford-Fulkerson 算法和 Edmonds-Karp 算法的基础。\nWeak Duality 弱对偶性（Weak Duality）在流量值特征（flow value characterization）中的应用是网络流问题的一个重要概念。它提供了流量值的一个上界。\n弱对偶性定理的内容如下：\n对于任何流网络和任何割（s-t cut），流量值总是小于或等于割的容量。换句话说，最大流的值总是小于或等于最小割的值。\n在流量值特征中，这个定理意味着我们可以通过寻找最小割来得到流量值的一个上界。这个上界对于理解和解决网络流问题非常有用，因为它提供了一个我们无法超过的流量值。\n此外，这个定理还证明了最大流最小割定理（Max-Flow Min-Cut Theorem）的一部分。最大流最小割定理是网络流问题中的一个重要定理，它表明在任何流网络中，最大流的值等于最小割的值。弱对偶性定理证明了这个定理的“小于等于”部分，而“等于”部分需要通过 Ford-Fulkerson 算法或其变种来证明。\nOptimality 所有穿过割的边要么是从 A 到 B 并且满流，要么是从 B 到 A 并且空流。\nPerfect Matchings 在图论中，\u0026ldquo;匹配\u0026rdquo;（Matching）是指图的一个边的子集，使得子集中的任意两条边都不共享顶点。这是一种将图中的一部分顶点配对的方式，每对配对都通过一条边连接。匹配不一定需要包含图中的所有顶点。\n\u0026ldquo;完美匹配\u0026rdquo;（Perfect Matching）是匹配的一种特殊情况。在完美匹配中，图的每个顶点都恰好与子集中的一条边相连。换句话说，如果一个图有 n 个顶点，那么它的一个完美匹配就会有 n/2 条边。\n完美匹配在许多问题中都有应用，例如在网络设计、任务分配、市场匹配等问题中。在这些问题中，我们通常希望找到一个完美匹配，使得某种成本或效益最优化。\n例如，二分图的最大匹配问题就是要找到一个最大的匹配，即一个最大的边集，使得集合中的任意两条边都不共享端点。这个问题可以通过将其转化为最大流问题来解决。\nBipartite Matching 二分匹配（Bipartite Matching）是图论中的一个重要概念，它是在二分图（Bipartite Graph）中进行的匹配。\n二分图是一种特殊的图，它的所有顶点可以被分成两个互不相交的集合，使得每一条边的两个端点分别属于这两个不同的集合。在二分图中进行匹配，就是找到边的集合，使得在这个集合中的任意两条边都不共享端点。\n二分匹配有许多实际应用，例如在任务分配、稳定婚姻问题、市场均衡等问题中都有应用。在这些问题中，我们通常希望找到一个最大的匹配，也就是包含最多边的匹配。\n加s和t就能当max-flow问题解了。\n\u0026ldquo;请说\u0026rsquo;相邻\u0026rsquo;而不是\u0026rsquo;连接\u0026rsquo;\u0026quot;：在图论中，\u0026ldquo;相邻\u0026quot;和\u0026quot;连接\u0026quot;这两个词有着不同的含义。如果两个节点之间有一条边，我们通常说这两个节点是\u0026quot;相邻\u0026quot;的。而\u0026quot;连接\u0026quot;通常指的是在一个图中，存在一条路径可以从一个节点到达另一个节点。\n\u0026ldquo;避免使用\u0026rsquo;任何\u0026rsquo;这个词\u0026rdquo;：在描述算法时，\u0026ldquo;任何\u0026quot;这个词可能会引起混淆。比如，如果我们说\u0026quot;任何节点都可以到达任何其他节点\u0026rdquo;，这可能会被误解为在图中存在一条从每个节点到每个其他节点的直接边，而实际上我们可能只是想表达在图中存在一条从每个节点到每个其他节点的路径。\nIntegrality Theorem 整数定理（Integrality Theorem）是网络流问题中的一个重要定理，它表明如果所有边的容量都是整数，那么存在一个最大流，使得每条边的流量也都是整数。\n如果 k 是整数，并且我们只考虑容量为 1 的边，那么每条边的流量 f(e) 必须是 0 或 1。原因是流量必须满足容量约束，也就是说，流量不能超过容量。因此，如果容量为 1，那么流量只能是 0 或 1。\n这个性质在解决一些特殊的网络流问题时非常有用，例如在匹配问题和路由问题中。在这些问题中，我们通常只关心是否存在一条边，而不关心边的具体容量，所以我们可以将所有边的容量设为 1，然后应用整数定理。\nMatch to Flow 这个定理表明，在图 G 中的最大匹配数等于在 G\u0026rsquo; 中的最大流量。这个定理的证明分为两部分：\n≤：将最大匹配转化为流量。匹配约束确保我们满足流量约束。匹配约束和匹配大小确保流量值等于匹配大小。\n≥：将最大流量转化为匹配。流量整数性确保我们不会选择边的分数部分。流网络的约束（容量，保守性）确保我们满足匹配约束（每个顶点最多只能与一个匹配边相邻）。流量值引理表明匹配的大小等于流量的值。\n这个定理说明了匹配问题和网络流问题之间的深刻联系。通过将匹配问题转化为网络流问题，我们可以使用网络流算法，如 Ford-Fulkerson 算法和 Edmonds-Karp 算法，来解决匹配问题。这种转化方法在解决一些复杂的组合优化问题时非常有用。\nDisjoint Paths 在图论中，\u0026ldquo;不相交路径\u0026rdquo;（Disjoint Paths）是指一组路径，其中任意两条路径都没有共享的顶点或边。换句话说，这些路径是完全独立的，它们不会在任何地方交叉或重叠。\n不相交路径的概念在许多问题中都有应用，例如在网络设计、路由问题、交通规划等问题中。在这些问题中，我们通常希望找到一组不相交的路径，以便最大化网络的吞吐量，或者避免交通拥堵。\n在有向图中，我们可以通过最大流算法来找出k条边不相交的路径。这个问题可以转化为一个容量为1的最大流问题。\n以下是证明过程：\n只需证明：假设我们有k条不相交的路径。我们可以在每条路径上路由一单位的流，不需要其他流。因此，最大流至少为k。\n如果证明：假设最大流至少为k。我们需要证明存在至少k条不相交的路径。为了证明这一点，我们可以对携带流的边的数量进行归纳。\n归纳基础：如果最大流为1，那么存在一条从s到t的路径。\n归纳步骤：假设对于所有小于k的最大流，都存在相应数量的不相交路径。现在，我们考虑最大流为k的情况。由于流的整数性质，我们知道存在一条边，其流量为1，我们可以移除这条边，并将总流量减少1。根据归纳假设，剩余的图存在k-1条不相交的路径。加上我们刚才移除的那条边，我们就找到了k条不相交的路径。\n因此，我们可以得出结论：在有向图中，存在k条边不相交的路径当且仅当最大流至少为k。\nScaling Max Flow 在解决最大流问题时，一种常用的策略是使用缩放（Scaling）技术。这种技术的基本思想是先解决一个简化的问题，然后逐步增加问题的规模，直到解决原始问题。\n在最大流问题中，缩放技术通常是这样实现的：\n首先，我们找到网络中最大的容量 C。\n然后，我们设置一个阈值，初始值为 C。\n我们只考虑容量大于或等于阈值的边，忽略其他边，然后使用 Ford-Fulkerson 算法或 Edmonds-Karp 算法找到这个简化网络的最大流。\n然后，我们将阈值减半，再次运行最大流算法。\n我们重复这个过程，直到阈值为 1。\n这种方法的优点是，每次迭代时，我们只需要考虑一部分边，这可以大大减少计算量。此外，由于我们是从大到小逐步减小阈值，所以我们可以利用前一次迭代的结果，这可以进一步提高效率。\n这种方法在处理大规模网络流问题时非常有效，特别是当网络中的容量差异很大时。\nEdmonds-Karp Algorithm 找最宽的路径。Dijkstra,$O(m^2lognlogF)$ 找最短的路径。BFS,$O(m^2n)$ Applications Circulation with Demands 多个源点和汇点的网络流问题是网络流问题的一个重要变种。在这个问题中，我们有多个源点和多个汇点，每个源点都有一个流出的需求，每个汇点都有一个流入的需求。我们的目标是找到一种流的分配方式，使得每个源点的流出等于需求，每个汇点的流入等于需求。\nHall’s Theorem 哈尔定理（Hall\u0026rsquo;s Theorem）是图论中的一个重要定理，主要用于解决二部图的完美匹配问题。它的内容如下：\n在一个二部图中，如果对于左侧的每个顶点集合，其邻接的右侧顶点集合的大小至少与其一样大，那么这个二部图存在一个完美匹配。\n更形式化地说，设 G=(V,E) 是一个二部图，V 可以分为两个部分 V1 和 V2。如果对于 V1 中的任意子集 S，都有 |N(S)| \u0026gt;= |S|，其中 N(S) 是 S 中所有顶点的邻接顶点集合，那么 G 中存在一个完美匹配。\n这个定理在组合优化、网络流和匹配理论等领域有广泛的应用。例如，它可以用来解决任务分配问题、婚配问题等。\nHall定理是用于解决二部图中的完美匹配问题的，而流网络中的需求循环问题则需要使用不同的方法来解决。\n在流网络中，每个节点都有一个需求，表示流入该节点的流量和流出该节点的流量之间的差值。一个需求循环是一个满足所有节点需求的流。\n要解决需求循环问题，我们可以使用以下步骤：\n添加一个新的源节点s和一个新的汇点t。 对于每个需求为d的节点v，如果d \u0026gt; 0，那么添加一条从s到v的边，容量为d；如果d \u0026lt; 0，那么添加一条从v到t的边，容量为-d。 在新的网络中找到一个最大流。如果这个最大流的值等于所有正需求的总和，那么原网络存在一个需求循环。否则，原网络不存在需求循环。 这个方法的正确性基于最大流最小割定理：在一个流网络中，最大流的值等于最小割的容量。在这个问题中，最小割就是将所有正需求的节点和所有负需求的节点分开的割，其容量就是所有正需求的总和。所以，如果最大流的值等于所有正需求的总和，那么就存在一个需求循环。反之，如果存在一个需求循环，那么最大流的值必然等于所有正需求的总和。\n","date":"2024-06-11T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/max-flow-min-cut-theorem/","title":"Max-Flow Min-Cut Theorem"},{"content":"面向对象编程（Object-Oriented Programming，OOP）是一种编程范式，它使用 \u0026ldquo;对象\u0026rdquo; 来设计软件和结构化代码。在面向对象编程中，每个对象都是一个特定类型的实例，每个类型可以定义其自己的属性（数据）和方法（函数）。\n以下是一个简单的 Python 面向对象编程的例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 class Person: def __init__(self, name, age): self.name = name self.age = age def say_hello(self): print(f\u0026#34;Hello, my name is {self.name} and I\u0026#39;m {self.age} years old.\u0026#34;) # 创建一个 Person 对象 alice = Person(\u0026#34;Alice\u0026#34;, 25) # 调用对象的方法 alice.say_hello() # 输出：Hello, my name is Alice and I\u0026#39;m 25 years old. 在这个例子中，Person 是一个类，它定义了两个属性（name 和 age）和一个方法（say_hello）。然后，我们创建了一个 Person 类的实例 alice，并调用了它的 say_hello 方法。\n面向对象编程的主要优点是它可以提高代码的可读性和可重用性，同时也使得软件更易于维护和开发。\n在面向对象编程中，继承和多态是两个非常重要的概念。\n继承是一种可以让一个类（子类）获取另一个类（父类）的属性和方法的机制。这样，我们可以创建一个通用的父类，然后创建更具体的子类来继承父类的特性。这可以减少代码重复，并提高代码的可读性和可维护性。\n在 Python 中，我们可以使用 class SubClass(SuperClass): 语法来实现继承：\n1 2 3 4 5 6 7 8 9 10 11 class Animal: def make_sound(self): pass class Dog(Animal): def make_sound(self): return \u0026#34;Woof!\u0026#34; class Cat(Animal): def make_sound(self): return \u0026#34;Meow!\u0026#34; 多态是指允许一个接口（在 Python 中是方法）被多种数据类型实现。这意味着我们可以定义一个接口，然后让多个类实现这个接口，每个类都有自己的实现方式。这使得我们可以在不知道对象具体类型的情况下，通过这个接口来使用对象。\n在上面的例子中，Animal 类定义了一个 make_sound 方法，然后 Dog 类和 Cat 类都实现了这个方法，每个类都有自己的实现方式。这就是多态的一个例子。我们可以这样使用：\n1 2 3 4 5 def animal_sound(animal): print(animal.make_sound()) animal_sound(Dog()) # 输出：Woof! animal_sound(Cat()) # 输出：Meow! 在这个例子中，animal_sound 函数可以接受任何实现了 make_sound 方法的对象，无论它是 Dog 类的实例还是 Cat 类的实例。这就是多态的强大之处。\n","date":"2024-06-11T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/object-oriented/","title":"Object Oriented"},{"content":"在 C 语言中，指针是一个变量，其值为另一个变量的地址。以下是一个例子，演示了如何创建一个指向整数的指针 dale，并修改其指向的值 xiaohuang 和 xiaodi：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #include \u0026lt;stdio.h\u0026gt; int main() { int xiaohuang = 1; // 定义一个整数变量 xiaohuang，并初始化为 1 int xiaodi = 2; // 定义一个整数变量 xiaodi，并初始化为 2 int *dale = \u0026amp;xiaohuang; // 定义一个指针变量 dale，并将其初始化为 xiaohuang 的地址 printf(\u0026#34;Before: xiaohuang = %d, xiaodi = %d\\n\u0026#34;, xiaohuang, xiaodi); // 输出 xiaohuang 和 xiaodi 的初始值 *dale = 0; // 使用指针 dale 修改 xiaohuang 的值为 0 dale = \u0026amp;xiaodi; // 将 dale 的指向改为 xiaodi 的地址 *dale = 0; // 使用指针 dale 修改 xiaodi 的值为 0 printf(\u0026#34;After: xiaohuang = %d, xiaodi = %d\\n\u0026#34;, xiaohuang, xiaodi); // 输出修改后的 xiaohuang 和 xiaodi 的值 return 0; } 在这个例子中，\u0026amp;xiaohuang 是取 xiaohuang 的地址，*dale 是取 dale 指向的值。所以 *dale = 0; 就是将 dale 指向的值（也就是 xiaohuang）改为 0。紧接着，dale = \u0026amp;xiaodi; 将 dale 的指向改为 xiaodi 的地址，然后 *dale = 0; 将 dale 指向的值（也就是 xiaodi）改为 0。\n","date":"2024-06-11T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/pointer/","title":"Pointer"},{"content":"反证法（Proof by contradiction）是一种常用的数学证明方法。它的基本思想是假设我们要证明的命题是错误的，然后通过逻辑推理得出矛盾，从而证明该命题是正确的。\n例如，我们可以用反证法证明 \u0026ldquo;√2 是无理数\u0026rdquo; 这个命题。证明过程如下：\n假设 √2 是有理数，那么它可以表示为两个互质整数的比，即 √2 = a/b，其中 a 和 b 是没有公因数的整数。 将等式两边平方，得到 2 = a^2 / b^2，即 a^2 = 2b^2。 这意味着 a^2 是偶数（因为它是2的倍数），所以 a 也是偶数（因为只有偶数的平方是偶数）。 因此，我们可以将 a 写成 2k（k 是整数），然后将它代入等式 a^2 = 2b^2，得到 (2k)^2 = 2b^2，即 4k^2 = 2b^2，简化后得到 b^2 = 2k^2。 这意味着 b^2 也是偶数，所以 b 也是偶数。 但是，我们一开始假设 a 和 b 是互质的，也就是说它们没有公因数。现在我们得出 a 和 b 都是偶数，这是一个矛盾。 因此，我们的假设（√2 是有理数）是错误的，所以 √2 是无理数。 这就是反证法的一个例子。\n","date":"2024-06-11T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/proof-by-contradiction/","title":"Proof by Contradiction"},{"content":"在编程中，\u0026ldquo;副作用\u0026rdquo;（Side Effect）是指函数或表达式在计算结果以外，对外部世界产生的影响。这些影响可能包括更改全局变量的值，修改输入参数，执行 I/O 操作，等等。 在 Python 中，许多操作和函数都可能产生副作用。以下是一些常见的例子：\n修改全局变量：在函数内部修改全局变量的值会产生副作用。 1 2 3 4 5 6 7 8 x = 1 def change_global(): global x x = 2 change_global() print(x) # 输出：2 修改可变类型的参数：如果函数接收一个可变类型（如列表或字典）的参数，并修改了它，那么这就是一个副作用。 1 2 3 4 5 6 def add_element(my_list, element): my_list.append(element) numbers = [1, 2, 3] add_element(numbers, 4) print(numbers) # 输出：[1, 2, 3, 4] I/O 操作：读写文件、打印到控制台、网络请求等 I/O 操作都会产生副作用。 1 2 3 4 5 def write_to_file(): with open(\u0026#39;file.txt\u0026#39;, \u0026#39;w\u0026#39;) as f: f.write(\u0026#39;Hello, World!\u0026#39;) write_to_file() # 这将在磁盘上创建或修改一个文件 修改类的实例属性：在类的方法中修改实例属性也是一种副作用。 1 2 3 4 5 6 7 8 9 10 class MyClass: def __init__(self): self.value = 0 def increment(self): self.value += 1 obj = MyClass() obj.increment() print(obj.value) # 输出：1 在编程时，我们通常应尽量避免副作用，因为它们会使代码更难理解和测试。无副作用的函数（也称为纯函数）只依赖于输入参数，并且只通过返回值与外部世界交互，这使得它们的行为更加可预测和可重用。\n","date":"2024-06-11T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/side-effect/","title":"Side Effect"},{"content":"语法糖是指在编程语言中添加的某种语法，这种语法对语言的功能并没有影响，但是更方便程序员使用。语法糖可以使代码更易读、更易写。\n在 JavaScript 中，有很多语法糖的例子：\n箭头函数：箭头函数是一种更简洁的函数语法，它还有一些其他特性，如不绑定自己的 this。 1 2 3 4 5 6 7 // 普通函数 function add(x, y) { return x + y; } // 箭头函数 const add = (x, y) =\u0026gt; x + y; 模板字符串：模板字符串提供了一种更方便的方式来创建包含变量的字符串。 1 2 3 4 5 let name = \u0026#39;Alice\u0026#39;; // 普通字符串 console.log(\u0026#39;Hello, \u0026#39; + name + \u0026#39;!\u0026#39;); // 模板字符串 console.log(`Hello, ${name}!`); 解构赋值：解构赋值语法是一种 JavaScript 表达式，可以方便地从数组或对象中提取数据，并赋值给变量。 1 2 let [a, b] = [1, 2]; let {name, age} = {name: \u0026#39;Alice\u0026#39;, age: 25}; 类语法：虽然 JavaScript 是基于原型的语言，但是 ES6 引入了类语法作为原型继承的语法糖。 1 2 3 4 5 6 7 8 9 class MyClass { constructor(x) { this.x = x; } myMethod() { return this.x; } } 这些语法糖可以使 JavaScript 代码更简洁、更易读，但是它们并没有改变 JavaScript 的核心机制。\n","date":"2024-06-11T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/syntactic-sugar/","title":"Syntactic Sugar"},{"content":"Tree 连着的没有方向的没有圈圈的图\nRooted Tree 有一个根节点\nParent, Child, Sibling Parent: 父节点 Child: 子节点 Sibling: 兄弟节点 Leaf: 没有子节点的节点 Ancestor, Descendant Ancestor: 祖先节点，一个path到根节点，我是我自己的祖先 Proper Ancestor: 除了自己的祖先 Descendant: 子孙节点 Proper Descendant: 除了自己的子孙 Node depth depth是对node说的，proper ancestor的数量，根节点的depth是0\nHeight height是对整个tree说的，最大的depth+1\nBinary Tree 每个节点最多有两个子节点的rooted tree\nBinary Search Tree 每个node都有一个key，可以重复 对于每个node，左子树的key都小于这个node的key，右子树的key都大于这个node的key Balanced Binary Tree 一啪啦实现方法，尽量让树的高度小，比如AVL tree，Red-Black tree\nO(log n)的search, insert, delete O(n)的space ","date":"2024-06-11T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/tree/","title":"Tree"},{"content":" Preprocessing Sentence segmentation Tokenization, subword tokenization Word normalization Inflectional vs derivational morphology Lemmatization vs stemming Stopword removal N-gram Language Model Derivation Smoothing techniques Add-k Absolute discounting Katz backoff Kneser-Ney smoothing Interpolation Text Classification Build a classifier Task Topic classification Sentiment analysis Native language identification Algorithms Naive Bayes, logistic regression, SVM kNN, neural networks Bias vs variance：欠拟合under和过拟合over的取舍 Evaluation Precision, recall, F1 Part of Speech Tagging English POS Closed vs open classes Tagsets Penn Treebank tagset Automatic taggers Rule-based Statistical Unigram, classifier-based, HMM Hidden Markov Model Probabilistic formulation: Emission \u0026amp; Transition Training Viterbi algorithm Generative vs discriminative models Feedforward Neural Network Formulation Tasks: Topic classifcation Language models POS tagging Word embeddings Convolutional networks Recurrent Neural Network Formulation RNN: language models LSTM: Functions of gates Variants Tasks: Text classification: sentiment analysis POS tagging Lexical Semantics Definition of word sense, gloss Lexical Relationship: Synonymy, antonymy, hypernymy, meronymy Structure of wordnet Word similarity Path lenght Depth information Information content Word sense unambiguation supervised, unsupervised Distributional Semantics Matrices: VSM, TF-IDF, word-word co-occurrence Association measures: PMI, PPMI Count-based method: SVM Neural method: skip-gram, CBOW Evaluation: Word similarity, analogy Contextual Representation Formulation with RNN ELMo BERT Objective Fine-tuning for downstream tasks Transformers Multi-head attention Second half:\nAttention Sequential model with attention Attention variants: Concat Dot product Scaled dot product Location-based Cosine similarity Global vs local attention Self-attention Machine Translation Statistical MT Neural MT with teacher forcing Transformer Mutli-head self-attention Position encoding Pretrained Language Models Encoder architecture BERT bidirectional context good for classification Encoder-decoder architecture Decoder architecture GPT unidirectional context good for generation Large Language Models In-context learning Step-by-step reasoning Human-feedback reinforcement Instruction following Named Entity Recognition Predict entities in a text Traditional ML methods Bi-LSTM with another RNN/CRF Multi-aspect NER Coreference Resolution 共指消解 Coreference, anaphora B-Cubed metric Question Answering and Reading Comprehension Knowledge-based QA Visual QA Spoken Language Understanding Attention RNNs Joint BERT Tri-level model Explainable NLU Vision Language Pretrained Model V-L Interaction Model Self-attention, co-attention, VSE Constrastive Language-Image Pretraining Ethics Sotial bias 刻板印象 Incivility 仇恨言论 Privacy Violation 歧视 Misinformation 谣言 Technological divide 发展不平衡 Vocab stemming:词干提取，去掉后缀，通常不是个词 lemmatisation:词形还原 morphology 詞法學 lexicon 字典 corpus 语料 tokenization 分词 entailment vs. contradiction 蕴涵与矛盾 neutral 中性 vanish 消失 distill 提炼 lexical 词汇的，与词汇或词语有关 semantic 语义的，与词语的含义或解释有关 syntactic 句法的，与句子结构有关 sentiment 情感，对某事物的态度 polysemy 一词多义 gloss 词义, from dictionary，词典中对词语含义的解释 synonymy 同义词 antonymy 反义词 hypernymy 上义词, is-a，是一个更一般的词 hyponymy 一个更具体的词 meronymy 下义词, is-part-of spectrum 范围 conference 共指，在文本中指代同一实体 anaphora 指代，一种语言现象，代替先前提到的词 utterence 话语 utter 说，发出声音 tedious 冗长的工作，乏味，枯燥 versality 可以在多种不同的情况和环境中使用，具有很高的适应性和灵活性 continuation 相连 patch-based 基于块的 interpretability 可解释性，白盒 explainability 可解释性，黑盒 monolingual 只使用一种语言的情况或者系统 sinusoidal 正弦的 proximal 接近的 miscellaneous 混杂的 antecedent 先行词, Trump anaphor 指代词, he pronominal 代词的 adjective 形容词 factoid 事实 intent 意图 clause 子句 toxicity 有毒 insult 侮辱 humiliation 羞辱 altered 改变 conjunction 连接词 conform 符合 genre 风格 spurious 伪造的 occurrence 出现 maginalisation 边缘化 nuance 细微差别 Information Bottleneck 信息瓶颈问题是指在机器学习模型中，模型在尝试压缩输入数据的同时，还要尽可能保留与目标输出相关的信息。这是一个权衡问题，因为模型需要找到一个平衡点，既能有效地压缩数据，又能保留足够的信息来进行准确的预测。\n","date":"2024-06-09T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/comp90042/","title":"COMP90042"},{"content":" classical planning (blind/heuristic): https://fai.cs.uni-saarland.de/hoffmann/papers/ki11.pdf PDDL relaxation reinforcement learning: https://gibberblot.github.io/rl-notes/index.html Vocabs acyclic 无环\nsystematics 系统的 / local 局部\nheuristic 启发式\nmonotonic 单调\npriority queue = min heap\nconformant 符合的\npolicy 策略，map from state to action, denoted by $\\pi$\nnegation 否定\nprecondition 前提条件\npropositional 命题\npredicate 谓词，return true/false\nschema 模式，define somthing\nmisplace 放错\ndominate 支配\ncorollary 推论\npoint-wise 逐点\npessimistic 悲观\nbenchmark 基准\nnovelty 新颖性\nprune 修剪\nvelocity 速度\nstochastic 随机\ntabular 表格\ndilemma 困境\nequilibria 平衡\n, set minus operation\npayoff 收益\nutility 效用\nNondeterministic Polynomial: 不确定多项式，没有已知的多项式时间算法可以在所有情况下找到一个解\nnon-deterministic: countless outcomes mixed strategy equilibria: 混合策略均衡\nnash equilibrium: 纳什均衡，每个玩家都在最佳响应下(pure strategy)，没有人会改变策略\n安全/目标感知/可接受/一致性 $h$ remaining cost to reach the goal, $*$ optimal\n假设$\\Pi$是一个计划任务，具有状态空间$\\Theta_{\\Pi} = (S, L, c, T, I, G)$，并且$h$是$\\Pi$的一个启发式。如果启发式满足以下条件，那么它被称为：\n安全（Safe）：如果对于所有$h(s) = \\infty$的状态$s \\in S$，都有$h^*(s) = \\infty$，则启发式被称为安全。\n目标感知（Goal-aware）：如果对于所有目标状态$s \\in S_G$，都有$h(s) = 0$，则启发式被称为目标感知。\n可接受（Admissible）：如果对于所有状态$s \\in S$，都有$h(s) \\leq h^*(s)$，则启发式被称为可接受。\n一致（Consistent）：如果对于所有$s \\xrightarrow{a} s\u0026rsquo;$的转移，都有$h(s) \\leq h(s\u0026rsquo;) + c(a)$，则启发式被称为一致。\n命题：假设$\\Pi$是一个计划任务，具有状态空间$\\Theta_{\\Pi} = (S, L, c, T, I, S_G)$，并且$h$是$\\Pi$的一个启发式。\n如果$h$是一致的和目标感知的，则$h$是可接受的。 如果$h$是可接受的，则$h$是目标感知的。 如果$h$是可接受的，则$h$是安全的。 没有其他这种形式的蕴含关系成立。 不可接受：最优的节点如果被高估，就会优先扩展其他节点，而错过最优。\n一致性：保证最优路径依次访问。\nSTRIPS: 问题是一个四元组$P = \\langle F,O,I,G \\rangle$： $F$ fact, 原子, 变量\n$O$ 或 $A$ operator, action, 操作符, 动作\n$I \\subseteq F$代表初始情况\n$G \\subseteq F$代表目标情况\n操作符$o \\in O$由以下表示：\n添加列表$Add(o) \\subseteq F$ 删除列表$Del(o) \\subseteq F$ 前提条件列表$Pre(o) \\subseteq F$ Relaxiation: Goal：Helps compute heuristic function。\n设$h^* : P \\rightarrow R^+_0 \\cup {\\infty}$是一个函数。$h^$的松弛是一个三元组$R= (P\u0026rsquo;,r,h\u0026rsquo;^)$，其中$P\u0026rsquo;$是任意集合，$r : P \\rightarrow P\u0026rsquo;$和$h\u0026rsquo;^* : P\u0026rsquo; \\rightarrow R^+_0 \\cup {\\infty}$是函数，对于所有的$\\Pi \\in P$，松弛启发式$h_R(\\Pi) := h\u0026rsquo;^(r(\\Pi))$满足$h_R(\\Pi) \\leq h^(\\Pi)$。松弛是：\n问题$P$：寻路。 更简单的问题$P\u0026rsquo;$：鸟类的寻路。 $P\u0026rsquo;$的完美启发式$h\u0026rsquo;^*$：直线距离。 转换$r$：假装你是一只鸟。 原生的，如果$P\u0026rsquo; \\subseteq P$且$h\u0026rsquo;^* = h^*$； 可有效构造的，如果存在一个多项式时间算法，给定$\\Pi \\in P$，可以计算$r(\\Pi)$； 可有效计算的，如果存在一个多项式时间算法，给定$\\Pi\u0026rsquo; \\in P\u0026rsquo;$，可以计算$h\u0026rsquo;^*(\\Pi\u0026rsquo;)$。 提醒：你有一个问题$P$，你希望估计其完美启发式$h^$。你定义了一个更简单的问题$P\u0026rsquo;$，其完美启发式$h\u0026rsquo;^$可以用来（可接受地！）估计$h^$。你定义了一个从$P$到$P\u0026rsquo;$的转换$r$。给定$\\Pi \\in P$，你通过$h\u0026rsquo;^(r(\\Pi))$来估计$h^*(\\Pi)$。\nnotation in this course:\n$\\Pi_s$：将初始状态替换为$s$的$\\Pi$，即，将$\\Pi = (F,A,c,I,G)$更改为$(F,A,c,s,G)$。\nc: clause, preconditions+effects 有关Quality Value的一些概念： Value：在强化学习中，value通常指的是一个状态的价值，也就是从这个状态开始，遵循某个策略能够获得的预期回报。\nQ-value：Q-value是对于状态-动作对(state-action pair)的价值的一种评估。也就是说，如果在某个状态下执行某个动作，然后遵循某个策略，能够获得的预期回报。\nQ-value table：Q-value table是一种数据结构，用于存储每个状态-动作对的Q-value。在表格型强化学习算法（如Q-learning）中，Q-value table是主要的数据结构。\nQ-value function：Q-value function是一个函数，它接受一个状态和一个动作作为输入，返回这个状态-动作对的Q-value。在函数逼近方法（如深度Q网络）中，Q-value function通常由神经网络来表示。\nQ-table：Q-table和Q-value table是同一个概念，只是名称不同。\n","date":"2024-06-09T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/comp90054/","title":"COMP90054"},{"content":"Learn some advanced algorithms and data structures.\nTreap\nAdmortized Analysis: Prepaid/Potential\nQuake Heap\nSplay Tree\nPerfect Hashing/Cuckoo Hashing\nRange Tree\nMin Cut/Max Flow\nKarger\u0026rsquo;s algorithm: 找最小割, 找多次取最优, 随机地找两个节点合并, 直到只剩下两个节点\nFord-Fulkerson algorithm: 最早的最大流算法, 重复地找增广路径, 直到找不到\nEdmonds-Karp algorithm: 用BFS找增广路径, complexity更低\nHall\u0026rsquo;s theorem: 一个二分图存在完美匹配当且仅当对于每一个子集, 子集的大小大于等于子集的邻居的大小\nReadings Karger\u0026rsquo;s Randomised Contraction algorithm: Chapter 13.2 of [KT] Flow networks, max flow, min cut and basic Ford-Fulkerson: Chapter 7.1 - 7.2 of [KT] and also Chapter 10.1 - 10.4 of [JE] Flow network applications (Bipartite Matching and Disjoint Paths): Chapter 7.5-7.6 of [KT] Capacity-Scaling: Chapter 7.3 of [KT]Edmonds-Karps algorithms: Chapter 10.6 of [JE] Circulation with demands: Chapter 7.7 of [KT] Linear Programming: https://jeffe.cs.illinois.edu/teaching/algorithms/notes/H-lp.pdf Approximation Algorithms: Chapter 1 of https://www.designofapproxalgs.com/book.pdf and see also Approximation Algorithms by Vazirani [JE] = https://jeffe.cs.illinois.edu/teaching/algorithms/book/Algorithms-JeffE.pdf [KT] = Algorithm Design by Kleinberg and Tardos Vocabs asymptotic notation: 渐进符号\nsubtle: 微妙的\nconjecture: 猜想\nconcave: 凹的\ninvalidate: 使无效\nconceptual: 概念上的\ndominate: 支配\ntrial: 尝试\nprime: 素数\nevict: 驱逐\ndisjoint: 不相交的\nfraction: 分数\ncascadinng: 级联\nauxilinary: 辅助的\nsink: 汇点\ndiscrepency: 差异\nincoporate: 合并\nconverse: 相反的\nsought: 寻找\npolytope: 多面体\nincident: 相邻的\n\u0026ldquo;Incident\u0026rdquo;：当我们说一条边和一个顶点是\u0026quot;incident\u0026quot;（相邻），意味着这条边的一个端点就是这个顶点。 \u0026ldquo;Adjacent\u0026rdquo;：当我们说两个顶点是\u0026quot;adjacent\u0026quot;（邻接），意味着存在一条边连接这两个顶点。同样，当我们说两条边是\u0026quot;adjacent\u0026quot;（邻接），意味着这两条边共享一个公共顶点。 feasible: 可行的\npolynomial: 多项式\ncomprise: 包括\nlogarithmic: 对数的\nrounding: 四舍五入\ninfeasible: 不可行的\nunbounded: 无界的\nreciprocal: 倒数\nincremental: 增量的\nconservation: 保守\nslackness: 松弛\nconservation node: 保守节点, a node that has the same flow in and out\nresidual graph: 残余图, a graph that represents the remaining capacity of each edge\naugmenting path: 增广路径, a path from source to sink in the residual graph\nfeasible flow: 可行流, a flow that satisfies the capacity constraints and conservation constraints\nperfect matching: 完美匹配, a matching that covers all the nodes\nbipartite graph: 二分图, a graph that can be divided into two sets such that all edges are between the two sets\ndisjoint paths: 不相交路径, paths that do not share any nodes\nvertex cover: 顶点覆盖, a set of vertices that covers all the edges\nmaximal matching: 最大匹配, a matching that cannot be extended by adding another edge\ncardinality 基数，集合中元素的数量\n","date":"2024-06-09T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/comp90077/","title":"COMP90077"},{"content":"Course notebook: https://tomkom.pages.gitlab.unimelb.edu.au/spatialdatamanagement/.\npostgreSQL postGIS QGIS Vocabs scope creep: 任务蔓延 schema: 数据库的结构 query: 查询 ACID: Atomicity 原子性, Consistency 一致性, Isolation 隔离性, Durability 持久性 waterfall: 瀑布模型, 一次性完成所有工作 agile: 敏捷开发, 分阶段完成工作 ERD/ERM: Entity Relationship Diagram/Model, 实体关系图/模型 entity, attribute, relationship: 实体, 属性, 关系 location: space and time position: reference to a coordinate system 地理學第一定律: 所有事物都與其他事物相關, 但是近處的事物比遠處的事物更相關 longitude: 经度 latitude: 纬度 altitude: 海拔 wgs84: 地球坐标系, 经典的经纬度 polynomial: 多项式 ployline: 折线 polygon: 多边形 vertex: 顶点 vector: 向量 raster: 栅格 sphere: 球体 spheroid: 椭球体 Coordinate system 因为板块漂移, 会导致地理坐标系的变化, 所以经纬度总是在更新\n","date":"2024-06-09T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/geom90008/","title":"GEOM90008"},{"content":" pure Strategy: single action\nmixed Strategy: probability distribution over actions\nweakly dominate: $\\leq$\nstrongly dominate: $\u0026lt;$\na weakly(strictly) dominant strategy: always better than any other strategy\nnash equilibrium: 每个agent都选了最优策略，其他agent不会改变策略\nindifference: 通过调整我的策略概率，改变对手的收益（payoff）期望，使无论对手如何选择，他的满意度（utility）都一样\nUtility Function U_i(a): what can agent i get from action a\nNormal Form Game 一轮，不知道对手的策略，只知道对手的utility function\nExtensive Form Game 广义形式博弈 轮流决策，所以知道对手的策略\nSubgame Perfect Equilibrium 子博弈完美均衡 当前玩家在他的回合的最优策略，对手在他的回合的最优策略。。。\nBackward Induction 反向归纳 1 2 3 4 5 6 7 8 9 10 11 12 13 输入：广义形式博弈 G = (N, Agt, S, s_0, A, T, r) 输出：每个状态 s ∈ S 的子博弈均衡 函数 BackwardInduction(s ∈ S): 如果 A(s) = ∅，则返回 r(s) best_child ← (-∞, ..., -∞) 对于每个 a ∈ A(s)： s\u0026#39; ← T(s,a) child_reward ← BackwardInduction(s\u0026#39;) 如果 child_reward(P(s)) \u0026gt; best_child(P(s))，则 best_child ← child_reward 返回 best_child 返回 BackwardInduction(s_0) Multi-agent Q-learning 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 输入：随机博弈 G = (S, s_0, A^1, ..., A^n, r^1, ..., r^n, Agt, P, γ) 输出：Q函数 Q^j，其中 j 是 self agent 初始化 Q^j 任意，例如，对于所有的状态 s 和联合动作 a，Q^j(s,a)=0 重复： s ← episode e 的第一个状态 重复（对于 episode e 的每一步）： 选择在 s 中应用的动作 a^j 例如，使用 Q^j 和一个多臂老虎机算法，如 ε-greedy 在状态 s 中执行动作 a^j 观察奖励 r^j 和新状态 s\u0026#39; Q^j(s,a) ← Q^j(s,a) + α * [r^j + γ * max_a\u0026#39; Q^j(s\u0026#39;,a\u0026#39;) - Q^j(s,a)] s ← s\u0026#39; 直到 episode e 结束（一个终止状态） 直到 Q 收敛 ","date":"2024-05-30T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/game-theory/","title":"Game Theory"},{"content":" h*: the optimal heuristic\nh pre\u0026amp;del: the heuristic ignoring preconditions and delete effects, adimissible and consistent, \u0026ldquo;subset sum\u0026rdquo; problem, NP-hard\nh goal_count: the number of goals not yet achieved, neither admissible nor consistent\nh+/h del: admitssible and consistent, 相当于MST, 每个state只访问一遍，也NP-hard\nh add: easily not admissible\nh max: easily too small\nh ff: use h add and h max\nRemoving preconditions and delete effects is efficiently constructive but not computable。\nh max和h add的table是不一样的，一个是最大值，一个是累加值。\nDelete Relaxation 忽略搜索中所有的delete效果，在发现goal之前减少重复的状态。\nState Dominance: 如果一个状态支配另一个状态，那么我们可以忽略支配状态。被包含了。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def greedyRelaxedPlan(problem): candidate_pq = util.PriorityQueue() init_state = problem.getStartState() init_path = [] candidate_pq.push((init_state,init_path),0) viewed = [] while not candidate_pq.isEmpty(): state,path = candidate_pq.pop() if problem.isGoalState(state): return path if state not in viewed: viewed.append(state) for child_state, child_action, _ in problem.getSuccessors(state): # ignore cost as we are blind child_path = path + [child_action] candidate_pq.push((child_state,child_path),0) return None Neither admissible nor consistent. 因为不保证optimal，只保证能找到解决方案。\nOptimal的都NP-hard。\nAdditive and Max Heuristics Additive: 相加子目标的启发式，明显不是admissible。 $h^{add}(s, g) = \\begin{cases} 0 \u0026amp; \\text{if } g \\subseteq s \\ \\min_{a \\in A, g \\in add_a} (c(a) + h^{add}(s, pre_a)) \u0026amp; \\text{if } |g| = 1 \\ \\sum_{g\u0026rsquo; \\in g} h^{add}(s, {g\u0026rsquo;}) \u0026amp; \\text{if } |g| \u0026gt; 1 \\end{cases}$\nMax: 选择子目标中最大的启发式。最难解决的子节点。 $h^{max}(s, g) = \\begin{cases} 0 \u0026amp; \\text{if } g \\subseteq s \\ \\max_{a \\in A, g \\in add_a} (c(a) + h^{max}(s, pre_a)) \u0026amp; \\text{if } |g| = 1 \\ \\max_{g\u0026rsquo; \\in g} h^{max}(s, {g\u0026rsquo;}) \u0026amp; \\text{if } |g| \u0026gt; 1 \\end{cases}$\n都goal-aware，因为h+ ∞时，h也是∞。\nBest Supporter Heuristic $bs_{s}^{max}(p) = argmin_{a\\in A,p \\in add_a}c(a)+h^{max}(s,pre_a)$\n$bs_{s}^{add}(p) = argmin_{a\\in A,p \\in add_a}c(a)+h^{add}(s,pre_a)$\n把$h_{add}$和$h_{max}$结合起来，选择最好的支持者。\nargmin: 在一系列动作里，选最小的h。\nBellman-Ford for hmax and hadd Bellman-Ford variant computing hadd for state s\n反复更新表Tadd，直到表中的值不再改变。在每次迭代中，对于每个目标状态g，都会计算一个新的值fi(g)，这个值是当前状态s到状态g的最短路径的估计值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def bellmanFordHadd(problem): states = problem.getStates() actions = problem.getActions() P = problem.getTransitionProbabilities() r = problem.getRewards() gamma = problem.getDiscount() theta = 0.01 Tadd = {s: 0 for s in states} while True: delta = 0 for s in states: v = Tadd[s] Tadd[s] = min([sum([r[s][a][s_prime] + gamma * Tadd[s_prime] for s_prime in states]) for a in actions]) delta = max(delta, abs(v - Tadd[s])) if delta \u0026lt; theta: break return Tadd Iterated Width Novelty：只考虑$w(s)$个状态变量atoms的变化情况。\n搜索直到目标状态的状态变量的数量。\n一个state的novelty：第一次出现的atom组合中的atom数量。the size of the smallest subset of atoms in s，that is true for the first time in search。\n","date":"2024-05-29T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/greedy-relaxed-planning/","title":"Greedy Relaxed Planning"},{"content":"Uniform Cost Search Priority Queue，最先被探索离起始节点最近（即路径成本最低）的节点。\nBreath First Search属于Uniform Cost Search的特例，即每个节点的路径成本都是1。\nUCS只看到了路径成本，没有考虑启发式。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def uniformCostSearch(problem): candidate_pq = util.PriorityQueue() init_state = problem.getStartState() init_path = [] candidate_pq.push((init_state,init_path),0) viewed = [] while not candidate_pq.isEmpty(): state,path = candidate_pq.pop() if problem.isGoalState(state): return path if state not in viewed: viewed.append(state) for child_state, child_action, child_cost in problem.getSuccessors(state): child_path = path + [child_action] candidate_pq.push((child_state,child_path),problem.getCostOfActions(child_path)) return None Greedy Best First Search BFS只看到了启发式，没有考虑路径成本。\nIf h=0，BFS是什么根据它的Priority Queue的实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def bestFirstSearch(problem, heuristic=nullHeuristic): candidate_pq = util.PriorityQueue() init_state = problem.getStartState() init_path = [] candidate_pq.push((init_state,init_path),heuristic(init_state, problem)) viewed = [] while not candidate_pq.isEmpty(): state,path = candidate_pq.pop() if problem.isGoalState(state): return path if state not in viewed: viewed.append(state) for child_state, child_action, _ in problem.getSuccessors(state): # ignore cost as we are blind child_path = path + [child_action] candidate_pq.push((child_state,child_path),heuristic(child_state, problem)) return None ","date":"2024-05-29T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/ucb-and-greedy-bfs/","title":"UCB and Greedy BFS"},{"content":"Lexical Semantics 词汇解释\nSynonymy 同义词 Antonymy 反义词 Hypernymy 上义词 Meronymy 下义词 WordNet A lexical database of English.\nWord Similarity 路径长度：在WordNet中，两个词之间的路径长度可以用来衡量它们的相似性。 深度信息：在WordNet中，词的深度（在词汇树中的位置）也可以用来衡量词的相似性。 信息内容：词的信息内容（在语料库中的频率）也可以用来衡量词的相似性。 Distributional Semantics 词汇和其上下文的共现信息\n","date":"2024-05-28T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/lexical-semantics-and-distributional-semantics/","title":"Lexical Semantics and Distributional Semantics"},{"content":"神经网络（Neural Network）是一种模拟人脑神经元工作方式的机器学习模型。它由大量的神经元（也称为节点或单元）组成，这些神经元按照一定的层次结构排列，包括输入层、隐藏层和输出层。\n每个神经元接收来自上一层神经元的输入，然后通过一个激活函数（如 Sigmoid、ReLU 等）处理这些输入，得到一个输出，这个输出再传递给下一层的神经元。\n神经网络的训练通常使用反向传播（Backpropagation）算法和梯度下降（Gradient Descent）算法。在训练过程中，神经网络通过不断调整神经元之间的连接权重，来最小化预测值和真实值之间的差异。\n神经网络可以处理非线性问题，适用于各种复杂的机器学习任务，如图像识别、语音识别、自然语言处理等。但是，神经网络的训练需要大量的数据和计算资源，而且模型的解释性较差，这是它的一些挑战。\nA Neural Network is a machine learning model that simulates the way neurons in the human brain work. It consists of a large number of neurons (also known as nodes or units) arranged in a certain hierarchical structure, including input layers, hidden layers, and output layers.\nEach neuron receives input from the neurons in the previous layer, then processes these inputs through an activation function (such as Sigmoid, ReLU, etc.) to produce an output, which is then passed on to the neurons in the next layer.\nNeural networks are typically trained using the Backpropagation algorithm and the Gradient Descent algorithm. During training, the neural network minimizes the difference between the predicted values and the actual values by continuously adjusting the connection weights between neurons.\nNeural networks can handle non-linear problems and are suitable for various complex machine learning tasks, such as image recognition, speech recognition, natural language processing, etc. However, the training of neural networks requires a large amount of data and computational resources, and the interpretability of the model is relatively poor, which are some of the challenges.\n前馈神经网络 前馈神经网络是一种基础的神经网络，信息只在一个方向上流动，从输入层到输出层。\n任务：\n主题分类：使用神经网络对文本或其他数据进行主题分类。\n语言模型：使用神经网络来理解和生成语言。\n词性标注：使用神经网络来识别文本中每个词的词性。\n词嵌入：一种表示词汇的技术，将词汇映射到向量空间，使得语义相近的词汇在向量空间中的距离也相近。\n卷积网络：一种特殊的神经网络，特别适合处理网格形式的数据，如图像。\n循环神经网络 循环神经网络是一种可以处理序列数据的神经网络，它可以利用前面的信息来影响后面的输出。\nRNN语言模型：使用循环神经网络来理解和生成语言，特别适合处理文本等序列数据。 LSTM： 门的功能：LSTM是一种特殊的RNN，它有三个门（输入门、遗忘门和输出门）来控制信息的流动。 变体：LSTM有多种变体，如GRU（门控循环单元），它简化了LSTM的结构。 任务： 文本分类：情感分析：使用RNN进行文本分类，如情感分析，判断文本的情感倾向。 词性标注：使用RNN来识别文本中每个词的词性。 非线性激活函数是神经网络中的关键组成部分，它可以帮助神经网络学习和逼近复杂的模式。非线性激活函数的主要目的是将输入信号转换为输出信号，但它不仅仅是复制输入到输出。它会修改或者变换输入的方式，使得可以适应网络的需要。 常见的非线性激活函数包括：\nReLU（Rectified Linear Unit）：这是最常用的激活函数，它将所有负值设为0，正值保持不变。\nSigmoid：这个函数将任何数值都映射到0和1之间，它在早期的神经网络中非常流行，但现在已经较少使用，因为它在输入值很大或很小的时候，梯度几乎为0，这会导致梯度消失问题。\nTanh（Hyperbolic Tangent）：这个函数将任何数值都映射到-1和1之间，它比sigmoid函数的输出范围更广，因此在某些情况下，它的性能比sigmoid函数更好。\nSoftmax：这个函数通常用在神经网络的输出层，特别是在处理多分类问题时。它可以将一组数值转换为概率分布。\nRegularization 正则化 L1 Norm L2 Norm Dropout LSTM Memory cell：记忆单元，用来存储信息 Hidden state：隐藏状态，用来传递信息 Forget gate：遗忘门，用来控制记忆单元中的信息是否被遗忘 Input gate：输入门，用来控制新的信息是否被存储到记忆单元中 Output gate：输出门，用来控制隐藏状态中的信息是否被传递到下一个时间步 ","date":"2024-05-28T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/neual-networks/","title":"Neual Networks"},{"content":"Part-of-Speech(词类) Colourless green ideas sleep furiously.\nOpen Classes (Content Words) Noun Verb Adjective Adverb Closed Classes (Function Words) (Fixed number of words) Preposition Determiner Pronoun Conjunction Interjection Ambiguity: A word can have multiple meanings. A sentence can have multiple interpretations.\n在自然语言处理（NLP）中，POS代表词性标注（Part-of-Speech Tagging）。词性标注是一种将每个词语与其语法范畴（即词性）相关联的过程。它是NLP中的一项基本任务，用于确定句子中每个单词的词类。\n常见的词性包括名词、动词、形容词、副词、介词、代词、冠词、连词等。通过进行词性标注，可以帮助计算机理解句子的结构和含义，为其他NLP任务（如句法分析、语义分析和机器翻译等）提供基础。\n以下是一个例子，展示了一句英文句子的词性标注示例：\n句子：I love eating ice cream.\n词性标注：PRON VERB VERB NOUN NOUN.\n在这个例子中，\u0026ldquo;I\u0026quot;被标注为代词（PRON），\u0026ldquo;love\u0026quot;和\u0026quot;eating\u0026quot;被标注为动词（VERB），\u0026ldquo;ice\u0026quot;和\u0026quot;cream\u0026quot;被标注为名词（NOUN）。\n词性标注可以通过使用基于规则的方法、基于统计的机器学习方法（如隐马尔可夫模型）或基于深度学习的方法（如循环神经网络和转换器模型）来实现。这个任务在NLP中具有广泛的应用，对于许多文本处理任务都是重要的预处理步骤。\nNN（noun）名词：cat（猫）、book（书）、table（桌子） VB（verb）动词：run（跑）、eat（吃）、sleep（睡觉） JJ（adjective）形容词：big（大的）、happy（快乐的）、red（红色的） RB（adverb）副词：quickly（快速地）、well（好地）、very（非常） DT（determiner）限定词：the（定冠词）、this（这个）、some（一些） CD（cardinal number）基数词：one（一）、three（三）、ten（十） IN（preposition）介词：on（在\u0026hellip;上）、with（和\u0026hellip;一起）、at（在\u0026hellip;处） PRP（personal pronoun）人称代词：I（我）、you（你）、he（他） MD（modal）情态动词：can（能够）、should（应该）、will（将会） CC（coordinating conjunction）并列连词：and（和）、but（但是）、or（或者） RP（particle）小品词：up（向上）、down（向下）、out（出去） WH（wh-pronoun）疑问代词：who（谁）、what（什么）、which（哪个） TO（to）不定式标记：to（去）、to（为了）、to（到） Penn Treebank 词性标记集 Penn Treebank 的词性标注集（POS tagset）是一种广泛使用的英文词性标注方法。\nCC：并列连词 (Coordinating conjunction) CD：基数词 (Cardinal number) DT：限定词 (Determiner) EX：存在句引导词 (Existential there) FW：外来词 (Foreign word) IN：介词或从属连词 (Preposition or subordinating conjunction) JJ：形容词 (Adjective) JJR：比较级形容词 (Adjective, comparative) JJS：最高级形容词 (Adjective, superlative) LS：列表项标记 (List item marker) MD：情态动词 (Modal) NN：名词, 单数或集数 (Noun, singular or mass) NNS：名词, 复数 (Noun, plural) NNP：专有名词, 单数 (Proper noun, singular) NNPS：专有名词, 复数 (Proper noun, plural) PDT：前限定词 (Predeterminer) POS：所有格结束 (Possessive ending) PRP：人称代词 (Personal pronoun) PRP$：所有格代词 (Possessive pronoun) RB：副词 (Adverb) RBR：副词, 比较级 (Adverb, comparative) RBS：副词, 最高级 (Adverb, superlative) RP：小品词 (Particle) SYM：符号 (Symbol) TO：to UH：感叹词 (Interjection) VB：动词, 原形 (Verb, base form) VBD：动词, 过去式 (Verb, past tense) VBG：动词, 现在分词或动名词 (Verb, gerund or present participle) VBN：动词, 过去分词 (Verb, past participle) VBP：动词, 非第三人称单数现在式 (Verb, non-3rd person singular present) VBZ：动词, 第三人称单数现在式 (Verb, 3rd person singular present) WDT：wh-限定词 (Wh-determiner) WP：wh-代词 (Wh-pronoun) WP$：wh-所有格代词 (Wh-pronoun, possessive) WRB：wh-副词 (Wh-adverb) ","date":"2024-05-28T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/part-of-speech-tagging/","title":"Part-of-Speech Tagging"},{"content":" w：word t：tag emission probability: $P(w|t)$ 从tag到word的概率 transition probability: $P(t|t\u0026rsquo;)$ 从上一个tag到当前tag的概率 Viterbi Algorithm 从最开始算起，每个tag的概率是由前一个tag的概率和从前一个tag到当前tag的概率相乘得到的。\n$\\hat{t} = \\arg\\max_{t} \\prod_{i=1}^{n} P(w_i|t)P(t|t\u0026rsquo;)$, $t\u0026rsquo;$是前一个tag, $\\hat{t}$是当前的估计值。\nGenerative vs Discriminative Tagger HMM是generative model，可以用来生成数据，无监督的学习。 discriminative model例如CRF，需要有监督的数据，可以学到更丰富的特征，大多数deep learning的模型都是discriminative model。 ","date":"2024-05-27T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/hidden-markov-model/","title":"Hidden Markov Model"},{"content":"Language Model To explain language, based on probability, for generation.\nQuery completion(搜索引擎) Optical character recognition(OCR) Translation N-gram $$P(w_1, w_2, \\cdots, w_n) = P(w_1)P(w_2|w_1)P(w_3|w_1, w_2) \\cdots P(w_n|w_1, w_2, \\cdots, w_{n-1})$$\nMaximum Likelihood Estimation $$P(w_i|w_{i-1}) = \\frac{C(w_{i-1}, w_i)}{C(w_{i-1})}$$\nUse special tags to denote the beginning and end of a sentence, i.e. \u0026lt;s\u0026gt;, \u0026lt;/s\u0026gt;.\nSmoothing Handle unseen words.\nLaplacian (add-one) smoothing\n$P(w_i|w_{i-1}) = \\frac{C(w_{i-1}, w_i) + 1}{C(w_{i-1}) + V}$\nAdd-k smoothing\n$P(w_i|w_{i-1}) = \\frac{C(w_{i-1}, w_i) + k}{C(w_{i-1}) + kV}$\nLidstone smoothing\nGeneralized Add-k, 所有非负实数 Absolute discounting\nBorrow a bit of probability mass from seen words to unseen words， 每个借一点，均摊给没见过的词 Katz Backoff\nUse lower-order n-gram Issue：低阶n-gram可能有很高概率，但此n-gram组合显然不会存在 Knser-Ney\nVersatility of lower-order n-gram, co-occur with many words 让更通用的低阶n-gram有更高的概率 contiuation probability $P_{cont}(w_i) = \\frac{|{w_{i-1}:C(w_{i-1}, w_i) \u0026gt; 0}|}{\\sum_{w_i}C(w_{i-1}, w_i)}$ Interpolation\nCombine lower-order n-gram 给不同阶的n-gram加权，相加 ","date":"2024-05-27T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/n-gram-language-model/","title":"N-gram Language Model"},{"content":"Preprocessing Word Sentence: words Document: sentences Corpus: documents Word Token: word instance Word Type: verb, noun, etc. Lexicon: word types Steps Remove unwnated formatting, i.e. HTML tags Sentecne segmentation, break text into sentences Tokenization, break sentences into words Normalization, transform words into canonical form, i.e. lower case Stopword removal, delete unwanted words, i.e., \u0026ldquo;the\u0026rdquo;, \u0026ldquo;I\u0026rdquo;, \u0026ldquo;.\u0026rdquo;, etc. Max Match Algorithm Greedily match the longest word in the dictionary. Used in the language withoout space between words, i.e. Chinese.\nByte Pair Encoding Iteratively merge the most frequent pair of bytes. Used in ChatGPT.\nAdv:\nData-informed tokenization Works for different languages Deals better with unknown words Disadv:\nRarer words will be split into subwords, even individual letter Word Normalization Goal: reduce vocabulary size, map different forms of a word to the same form\n形态处理（Morphological processing）通常包括词干提取（stemming）和词形还原（lemmatization）\nLowercasing Remove morphology, i.e. \u0026ldquo;running\u0026rdquo; -\u0026gt; \u0026ldquo;run\u0026rdquo; Correct spelling, i.e. \u0026ldquo;colour\u0026rdquo; -\u0026gt; \u0026ldquo;color\u0026rdquo; Expand abbreviations, i.e. \u0026ldquo;can\u0026rsquo;t\u0026rdquo; -\u0026gt; \u0026ldquo;cannot\u0026rdquo; Inflectional Morphology(屈折形态) It creates grammatical variants of a word, i.e. \u0026ldquo;run\u0026rdquo; -\u0026gt; \u0026ldquo;running\u0026rdquo;, \u0026ldquo;ran\u0026rdquo;, \u0026ldquo;runs\u0026rdquo;\nNouns, verbs, adjectives, adverbs\u0026hellip;\nLemmatization(词形还原) To remove inflection.\nLemma(词元): the uninflated form\nDerivational Morphology(派生形态) It creates new words.\nChange the lexical category(), i.e. \u0026ldquo;happy\u0026rdquo; -\u0026gt; \u0026ldquo;happiness\u0026rdquo; Change the meaning, i.e. \u0026ldquo;happy\u0026rdquo; -\u0026gt; \u0026ldquo;unhappy\u0026rdquo; Stemmization(词干提取) To remove derivation.\nStem(词干): the root form\nThe Porter Stemmer most widely used in English\nC: consonant(辅音) V: vowel(元音) m: measure $C^m[V]$ Stopword Removal Typically in bag-of-words model\nAll closed-class or function words, any high frequency words\n","date":"2024-05-27T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/preprocessing/","title":"Preprocessing"},{"content":" Topic classification Sentiment analysis Native language identification Natual language inference Automatic fact-checking Paraphrase Topic Classification Motivation: library science, information retrieval, etc. Classes: topic categories Features: bag-of-words, n-grams, etc. Corpus: reuters news corpus, pubmed abstracts, tweets with hashtags Sentiment Analysis Motivation: opinion mining, business analytics Classes: positive, negative, neutral Features: n-grams, polarity lexicons, etc. Corpus: movie reviews, SEMEVAL twitter polarity dataset Native Language Identification Motivation: forensic linguistics, educational applications Classes: native languages Features: character n-grams, syntactic features (POS), phonological features Corpus: TOEFL/IELTS essays Natural Language Inference (textual entailment 文本蕴含) Motivation: language understanding Classes: entailment, contradiction, neutral Features: word overlap, length difference, etc. Corpus: SNLI, MultiNLI Build a Text Classifier Identify the task Collect and preprocess data Annotation Select features Select an algorithm Train and tune the model Evaluate the model Naive Bayes Classifier assume independence between features\n$$P(c|d) = \\frac{P(d|c)P(c)}{P(d)}$$\nPros:\nFast, simple Robust, low-variance Optimal if independence holds Cons:\nRarely holds Low accuracy Smoothing needed for unseen Logistic Regression $$P(c|d) = \\frac{1}{1 + e^{-\\sum_{i=1}^n w_i x_i}}$$\nPros:\nBetter performance Cons:\nSlow Scaling needed Regularization needed for overfitting Support Vector Machine To find the hyperplane that maximizes the margin\nPros:\nFast and accurate Non-linear kernel Work well in big data Cons:\nMulti-class classification Scaling needed Imbalanced data Interpretability K-Nearest Neighbors Euclidean distance, cosine similarity\nProbs:\nSimple No training needed Multi-class classification Optimal with infinite data Cons:\nSet k Imbalanced classes Slow Decision Tree Greedy maxmize information gain\nPros:\nFast Non-linear Good for small data Feature scaling irrelevant Cons:\nNot that interpretable Redundant features Not competitive for big data Random Forest Pros:\nBetter than decision tree Parallelizable Cons:\nSame as decision tree Neural Network Pros:\nPowerful Cons:\nHyperparameters Training time Overfitting Evaluation Accuracy\n$$\\frac{TP + TN}{TP + TN + FP + FN}$$\nPrecision\n$$\\frac{TP}{TP + FP}$$\nRecall\n$$\\frac{TP}{TP + FN}$$\nF1-score\n$$\\frac{2 \\times \\text{precision} \\times \\text{recall}}{\\text{precision} + \\text{recall}}$$\n","date":"2024-05-27T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/text-classification/","title":"Text Classification"},{"content":"A*算法（带有重复检测和重新打开） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 设 open 为新的优先级队列，按照 g(state(σ)) + h(state(σ)) 升序排列 open.insert(make-root-node(init())) 设 closed 为空集 设 best-g 为空集 /* 将状态映射到数字 */ 当 open 不为空时： σ := open.pop-min() 如果 state(σ) 不在 closed 中或 g(σ) \u0026lt; best-g(state(σ))： /* 如果 g 更好则重新打开；注意所有具有相同状态但 g 较差的 σ′ 都在 open 中位于 σ 后面，并且在轮到它们时将被跳过 */ closed := closed ∪{state(σ)} best-g(state(σ)) := g(σ) 如果 is-goal(state(σ))：返回 extract-solution(σ) 对于每个 (a,s′) ∈succ(state(σ))： σ′ := make-node(σ,a,s′) 如果 h(state(σ′)) \u0026lt; ∞：open.insert(σ′) 返回 unsolvable 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def aStarSearch(problem, heuristic=nullHeuristic): \u0026#34;\u0026#34;\u0026#34;Search the node that has the lowest combined cost and heuristic first.\u0026#34;\u0026#34;\u0026#34; myPQ = util.PriorityQueue() startState = problem.getStartState() startNode = (startState, 0, []) myPQ.push(startNode, heuristic(startState, problem)) best_g = dict() while not myPQ.isEmpty(): node = myPQ.pop() state, cost, path = node if (not state in best_g) or (cost \u0026lt; best_g[state]): best_g[state] = cost if problem.isGoalState(state): return path for succ in problem.getSuccessors(state): succState, succAction, succCost = succ new_cost = cost + succCost newNode = (succState, new_cost, path + [succAction]) myPQ.push(newNode, heuristic(succState, problem) + new_cost) return None # Goal not found If h=0, A* is equivalent to Uniform Cost Search.\nIf h admissible, A* is optimal. 因为我们的h比最优h小，在达到最优h之前，我们已经尝试过这个状态。\nWeighted A*算法 给heuristic函数加权，以调整搜索的速度。\nw越大，搜索越快，但可能会错过最优解，w越小，搜索越慢，但更有可能找到最优解。\nw=0时，等价于Uniform Cost Search。\nw to ∞时，等价于Greedy Best First Search。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def weightedAStarSearch(problem, heuristic=nullHeuristic, weight=1): \u0026#34;\u0026#34;\u0026#34;Search the node that has the lowest combined cost and heuristic first.\u0026#34;\u0026#34;\u0026#34; myPQ = util.PriorityQueue() startState = problem.getStartState() startNode = (startState, 0, []) myPQ.push(startNode, weight * heuristic(startState, problem)) best_g = dict() while not myPQ.isEmpty(): node = myPQ.pop() state, cost, path = node if (not state in best_g) or (cost \u0026lt; best_g[state]): best_g[state] = cost if problem.isGoalState(state): return path for succ in problem.getSuccessors(state): succState, succAction, succCost = succ new_cost = cost + succCost newNode = (succState, new_cost, path + [succAction]) myPQ.push(newNode, weight * heuristic(succState, problem) + new_cost) return None # Goal not found 爬山算法 local最优。\n1 2 3 4 5 6 σ := make-root-node(init()) 永远执行以下操作： 如果 is-goal(state(σ))： 返回 extract-solution(σ) Σ′ := {make-node(σ,a,s′) |(a,s′) ∈succ(state(σ)) } σ := 选择 Σ′ 中 h 值最小的元素 /* （随机打破平局） */ ","date":"2024-05-02T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/a-and-hill-climbing/","title":"A* and Hill Climbing"},{"content":"广度优先搜索（BFS） 队列，先进先出，后进后出。\nOptimal when costs are uniform\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def breadthFirstSearch(problem): candidate_queue = util.Queue() init_state = problem.getStartState() init_path = [] candidate_queue.push((init_state,init_path)) viewed = [] while not candidate_queue.isEmpty(): state,path = candidate_queue.pop() if problem.isGoalState(state): return path if state not in viewed: viewed.append(state) for child_state, child_action, _ in problem.getSuccessors(state): # ignore cost as we are blind child_path = path + [child_action] candidate_queue.push((child_state,child_path)) return None 深度优先搜索（DFS） 栈，先进后出，后进先出。\n搜索空间可能无限大（无限深）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def depthFirstSearch(problem): candidate_stack = util.Stack() init_state = problem.getStartState() init_path = [] candidate_stack.push((init_state,init_path)) viewed = [] while not candidate_stack.isEmpty(): state,path = candidate_stack.pop() if problem.isGoalState(state): return path if state not in viewed: viewed.append(state) for child_state, child_action, _ in problem.getSuccessors(state): # ignore cost as we are blind child_path = path + [child_action] candidate_stack.push((child_state,child_path)) return None ","date":"2024-05-02T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/bfs-and-dfs/","title":"BFS and DFS"},{"content":" Insertion: O(1) expected, O(n) worst case Search: O(n) expected, O(n) worst case Deletion: O(n) expected, O(n) worst case 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 class DynamicArray: def __init__(self): self.n = 0 # Number of elements self.capacity = 1 # Initial capacity self.A = self._make_array(self.capacity) def __len__(self): return self.n def __getitem__(self, k): if not 0 \u0026lt;= k \u0026lt; self.n: raise IndexError(\u0026#39;invalid index\u0026#39;) return self.A[k] def insert(self, element): \u0026#34;\u0026#34;\u0026#34; element = (id,key) \u0026#34;\u0026#34;\u0026#34; if self.n == self.capacity: self._resize(2 * self.capacity) self.A[self.n] = element self.n += 1 def delete(self, keydel): for i in range(self.n): if self.A[i][1] == keydel: self.A[i], self.A[self.n - 1] = self.A[self.n - 1], self.A[i] self.n -= 1 if self.n \u0026gt; 0 and self.n \u0026lt;= self.capacity // 4: self._resize(self.capacity // 2) break def search(self, keysch): for element in self.A[:self.n]: if element[1] == keysch: return element return None def _resize(self, new_cap): B = self._make_array(new_cap) for k in range(self.n): B[k] = self.A[k] self.A = B self.capacity = new_cap def _make_array(self, new_cap): return [None] * new_cap ","date":"2024-05-02T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/dynamic-array/","title":"Dynamic Array"},{"content":"Markov Decision Processes（MDPs）马尔可夫决策过程 MDP是完全可观察的，概率状态模型：\n状态空间 $S$ 初始状态 $s_0 \\in S$ 一组目标状态 $G \\subseteq S$ 在每个状态 $s \\in S$ 中可应用的动作 $A(s) \\subseteq A$ 对于 $s \\in S$ 和 $a \\in A(s)$，有转移概率 $P_a(s\u0026rsquo;|s)$ 动作成本 $c(a,s) \u0026gt; 0$\n其中：\n解决方案是将状态映射到动作的函数（策略）\n最优解最小化预期的前往目标的成本\nPartially Observable MDPs (POMDPs) 部分可观察的马尔可夫决策过程 POMDP是部分可观察的，概率状态模型：\n状态 $s \\in S$ 在每个状态 $s \\in S$ 中可应用的动作 $A(s) \\subseteq A$ 对于 $s \\in S$ 和 $a \\in A(s)$，有转移概率 $P_a(s\u0026rsquo;|s)$ 初始信念状态 $b_0$ 最终信念状态 $b_f$ 由概率 $P_a(o|s)$，$o \\in Obs$ 给出的传感器模型\n其中：\n信念状态是关于 $S$ 的概率分布 解决方案是将信念状态映射到动作的策略 最优策略最小化从 $b_0$ 到 $G$ 的预期成本\nsee also: https://gibberblot.github.io/rl-notes/single-agent/MDPs.html\nValue Iteration 一种动态规划算法，用于计算MDP的最优策略。\n1 2 3 4 5 6 7 8 9 10 11 12 def value_iteration(states, actions, P, r, gamma, theta): V = {s: 0 for s in states} # Initialize value function while True: delta = 0 for s in states: v = V[s] V[s] = max(sum(P[s][a][s_prime] * (r[s][a][s_prime] + gamma * V[s_prime]) for s_prime in states) for a in actions[s]) delta = max(delta, abs(v - V[s])) if delta \u0026lt; theta: # Check for convergence break return V Bellman Optimality Equation $ V^*(s) = \\max_{a \\in A(s)} \\sum_{s\u0026rsquo;} P_a(s\u0026rsquo;|s) \\left[ R_a(s\u0026rsquo;|s) + \\gamma V^{*}{(s\u0026rsquo;)} \\right] $\n所有可能的下一个状态的概率 动作的奖励 下一个状态的价值 x 折扣，前一个iteration存储的价值 Q-Value 对于每个状态 $s \\in S$，其一个可能动作 $a \\in A(s)$ 的质量是：\n$ Q(s,a) = \\sum_{s\u0026rsquo;} P_a(s\u0026rsquo;|s) \\left[ R_a(s\u0026rsquo;|s) + \\gamma V^*(s\u0026rsquo;) \\right] $\n其中 $\\gamma$ 是折扣，越接近1，越重视长期奖励，越接近0，越重视短期奖励。\n1 2 3 4 0.95, 0.9025, 0.857375, 0.81450625... 0.9, 0.81, 0.729, 0.6561... 0.8, 0.64, 0.512, 0.4096... 0.7, 0.49, 0.343, 0.2401... Policy $\\pi(s) = arg max Q(s,a)$\nMulti-Armed Bandit 平行地尝试多个动作，平衡exploitation和exploration。\nminimising regret，没有选择最佳动作的损失\n输入: 多臂老虎机问题 $M = {X_{i,k}, A, T}$ 输出: Q函数 $Q$ 初始化 $Q$ 为任意值; 例如，对所有的臂 $a$，$Q(a) \\leftarrow 0$ 初始化 $N$ 为任意值; 例如，对所有的臂 $a$，$N(a) \\leftarrow 0$ $k \\leftarrow 1$ while $k \\leq T$ do\n$\\quad$ $a \\leftarrow$ 在第 $k$ 轮选择一个臂\n$\\quad$ 在第 $k$ 轮执行臂 $a$ 并观察奖励 $X_{a,k}$\n$\\quad$ $N(a) \\leftarrow N(a) + 1$\n$\\quad$ $Q(a) \\leftarrow Q(a) + \\frac{1}{N(a)} [X_{a,k} - Q(a)]$\n$\\quad$ $k \\leftarrow k + 1$\nend while\n$\\epsilon$-greedy，以 $1-\\epsilon$ 的概率选择最佳动作，以 $\\epsilon$ 的概率选择随机动作\n$\\epsilon$-greedy with decay，随着时间的推移，减少 $\\epsilon$ 的值\nUCB\n$\\text{argmax}_{a}\\left(Q(a) + \\sqrt{\\frac{2 \\ln t}{N(a)}}\\right)$\nQ-Learning Input: MDP $M = \\langle S, s_0, A, P_a(s\u0026rsquo; | s), r(s, a, s\u0026rsquo;) \\rangle$ Output: Q-function $Q$ Initialise $Q$ arbitrarily; e.g., $Q(s, a) \\leftarrow 0$ for all $s$ and $a$ repeat\n$\\quad$ $s \\leftarrow$ the first state in episode $e$\n$\\quad$ repeat (for each step in episode $e$)\n$\\quad\\quad$ Select action $a$ to apply in $s$; e.g. using $Q$ and a multi-armed bandit algorithm such as $\\epsilon$-greedy\n$\\quad\\quad$ Execute action $a$ in state $s$\n$\\quad\\quad$ Observe reward $r$ and new state $s\u0026rsquo;$\n$\\quad\\quad$ $\\delta \\leftarrow r + \\gamma \\cdot \\max_{a\u0026rsquo;} Q(s\u0026rsquo;, a\u0026rsquo;) - Q(s, a)$\n$\\quad\\quad$ $Q(s, a) \\leftarrow Q(s, a) + \\alpha \\cdot \\delta$\n$\\quad\\quad$ $s \\leftarrow s\u0026rsquo;$\n$\\quad$ until $s$ is the last state of episode $e$ (a terminal state)\nuntil $Q$ converges\n$max_{a\u0026rsquo;} Q(s\u0026rsquo;, a\u0026rsquo;)$ 也可以写成 $V(s\u0026rsquo;)$，即下一个状态的价值 SARSA Input: MDP $M = \\langle S, s_0, A, P_a(s\u0026rsquo; | s), r(s, a, s\u0026rsquo;) \\rangle$ Output: Q-function $Q$ Initialise $Q$ arbitrarily; e.g., $Q(s, a) \\leftarrow 0$ for all $s$ and $a$ repeat\n$\\quad$ $s \\leftarrow$ the first state in episode $e$\n$\\quad$ Choose $a$ from $s$ using policy derived from $Q$ (e.g., $\\epsilon$-greedy)\n$\\quad$ repeat (for each step in episode $e$)\n$\\quad\\quad$ Take action $a$, observe $r$, $s\u0026rsquo;$\n$\\quad\\quad$ Choose $a\u0026rsquo;$ from $s\u0026rsquo;$ using policy derived from $Q$ (e.g., $\\epsilon$-greedy)\n$\\quad\\quad$ $\\delta \\leftarrow r + \\gamma \\cdot Q(s\u0026rsquo;, a\u0026rsquo;) - Q(s, a)$\n$\\quad\\quad$ $Q(s, a) \\leftarrow Q(s, a) + \\alpha \\cdot \\delta$\n$\\quad\\quad$ $s \\leftarrow s\u0026rsquo;$, $a \\leftarrow a\u0026rsquo;$\n$\\quad$ until $s$ is the last state of episode $e$ (a terminal state)\nuntil $Q$ converges\nQ-Learning是off-policy，因为on当前策略下的Q值，对当前策略更乐观 SARSA是on-policy，所以off了当前策略下的Q值，更保守 n-step reinforcement learning 记账，在n-step后再一起更新Q值。\nMCTS Selection：选择一个节点，直到找到一个未扩展的节点 Expansion：扩展一个未扩展的节点 Simulation：模拟一个随机游戏，直到结束 Backpropagation：更新所有访问的节点的值 offline：完成所有模拟后再选择最佳动作\nonline：每次模拟后选择最佳动作，继续对新的节点进行模拟。在下次选择时，同时也利用了之前的模拟结果，MCTS是online的。\n用平均值更新：新Q = 旧Q + 学习率 * 误差，实际上就是平均值\nUCT 用UCB来select。\n$\\text{argmax}_{a \\in A(s)} Q(s,a) + 2 C_p \\sqrt{\\frac{2 \\ln N(s)}{N(s,a)}}$ where $C_p$ 自己选，看是更偏向exploration还是exploitation\nLinear Q-functionn Approximation ## features = ## states * ## actions\n$Q(s,a) = f^T w = \\sum_{i=1}^{n} f_i(s,a) w_i$\nUpdate $w \\leftarrow w + \\alpha \\delta f(s,a)$ where $\\delta = r + \\gamma \\max_{a\u0026rsquo;} Q(s\u0026rsquo;,a\u0026rsquo;) - Q(s,a)$ if Q-learning $\\delta = r + \\gamma Q(s\u0026rsquo;,a\u0026rsquo;) - Q(s,a)$ if SARSA\nShaped Reward $Q(s,a) \\leftarrow Q(s,a) + \\alpha [r + \\underbrace{F(s,s\u0026rsquo;)}{\\text{additional reward}} + \\gamma \\max{a\u0026rsquo;} Q(s\u0026rsquo;,a\u0026rsquo;) - Q(s,a)]$\nPotential-based Reward Shaping $F(s,s\u0026rsquo;) = \\gamma \\Phi(s\u0026rsquo;) - \\Phi(s)$\nFor example, in Gridworld, $\\Phi(s) = 1 - \\frac{|x(g) - x(s)| + |y(g) - y(s)|}{width + height - 2}$\nPolicy Iteration 魔改bellman方程，将所有动作可能性替换成当前策略下的动作。\n","date":"2024-05-02T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/mdps/","title":"MDPs"},{"content":" Tree + Heap = Treap Insertion: O(log n) expected, O(n) worst case Search: O(log n) expected, O(n) worst case Deletion: O(log n) expected, O(n) worst case treap的key是有用的数据；priority是随机生成的值，用于保持treap的平衡。\nOperations Insertion 加到叶子节点，然后向上旋转，直到满足treap的性质。\nDeletion 找到要删除的节点，把priority设为无穷大，然后旋转，直到满足treap的性质。此时，要删除的节点就变成了叶子节点，然后删除。\nSearch 和BST一样，递归地搜索左子树或右子树。\nJoin 搞一个假的节点，priority设为无穷大，然后把两个treap的根节点作为左右子树，然后旋转，直到满足treap的性质。\nSplit 把要split的key找到，设成无穷小，然后旋转，直到满足treap的性质。此时，这个key到根节点了。\nImplementation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 import random class Node: def __init__(self, id, key, priority): self.id = id self.key = key self.priority = priority self.left = None self.right = None class Treap: def __init__(self): self.root = None def _left_rotate(self, node): right_child = node.right node.right = right_child.left right_child.left = node return right_child def _right_rotate(self, node): left_child = node.left node.left = left_child.right left_child.right = node return left_child def insert(self, element): node = Node(element[0], element[1], random.random()) if not self.root: self.root = node return self.root = self._insert_node(self.root, node) def _insert_node(self, root, node): if not root: return node if node.key \u0026lt; root.key: root.left = self._insert_node(root.left, node) if root.left.priority \u0026gt; root.priority: root = self._right_rotate(root) else: root.right = self._insert_node(root.right, node) if root.right.priority \u0026gt; root.priority: root = self._left_rotate(root) return root def delete(self, keydel): self.root = self._delete_node(self.root, keydel) def _delete_node(self, root, keydel): if not root: return None if keydel \u0026lt; root.key: root.left = self._delete_node(root.left, keydel) elif keydel \u0026gt; root.key: root.right = self._delete_node(root.right, keydel) else: if not root.left and not root.right: root = None elif not root.left: root = root.right elif not root.right: root = root.left else: if root.left.priority \u0026lt; root.right.priority: root = self._right_rotate(root) root.right = self._delete_node(root.right, keydel) else: root = self._left_rotate(root) root.left = self._delete_node(root.left, keydel) return root def search(self, key): return self._search_node(self.root, key) def _search_node(self, root, key): if not root: return None if root.key == key: return (root.id, root.key) elif key \u0026lt; root.key: return self._search_node(root.left, key) else: return self._search_node(root.right, key) ","date":"2024-05-02T00:00:00Z","permalink":"https://shyu216.github.io/aquamega/p/treap/","title":"Treap"}]